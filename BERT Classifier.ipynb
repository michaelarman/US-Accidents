{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8noPxzi65kSQ"
   },
   "source": [
    "# Using BERT to Classify the Severity of an Accident in US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will try using BERT to classify the Severity of an Accident based on the Description text of the data. This can be useful for businesses and emergency paramedics so they can prioritize and get to the location quicker. This along with the other notebook where we create a model to predict the location of an accident can be useful for tow truck companies as well as paramedics and optimize their response rate.\n",
    "\n",
    "BERT was used because it is very accurate compared to older NLP techniques. It vectorizes (encodes) our inputs and then we put it in our deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KL7ZciFOCz-w",
    "outputId": "b39e4222-aca0-4453-d2a5-f16ba19dd4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mmWABm-3556s",
    "outputId": "e734c1d0-b4c0-4a2e-be5e-121798a2a933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 8.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 21.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 16.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 60.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=f03f03bccbd1f91257e165b4b4c1d6a9be6b9f252cb04412241dba280bdf062b\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86a4fo-s5kSW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_RvU2iWy5kSp",
    "outputId": "45117373-1277-4e8b-c802-d72d1d1c2e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNmDIDwW5kS9"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhSVMfsZ5kTA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/datasets/US_Accidents_Dec19.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aSdDgRme6-Gt",
    "outputId": "af589821-3dd5-4813-8795-7399c2302fd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2974335, 49)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "09AzikJe5kTO",
    "outputId": "da677564-acfb-47fd-cf95-78b5897c5d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['Description'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p2eNun0s5kTa",
    "outputId": "c3b769bf-dc8f-46ab-8c49-4f88ae3f5aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['Severity'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcOSdNT55kTm"
   },
   "outputs": [],
   "source": [
    "df = df[['Description','Severity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhLUQnmH5kT4"
   },
   "outputs": [],
   "source": [
    "# drop that one row\n",
    "df = df.dropna(subset=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ml4SgaW5kUH"
   },
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.Description.values\n",
    "labels = df.Severity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "40f8285db49845b69ed7cc52ab35612f",
      "7723bccb180d49f0a0954200c8f7cf05",
      "b7a35f3310d54025ad3524ec1ebfc82e",
      "3c9280a2c3ca46c1a5cd6c30e04e4341",
      "0236d515a0bd4daab9a971b856c5e1cd",
      "7f34dd57f16b443c819186b2e8cccb22",
      "2eab9494b8dd4e3a8b476f35511311dd",
      "b09914bc13bf4bf490704cf72ba714c2"
     ]
    },
    "colab_type": "code",
    "id": "OshC19JA5kUW",
    "outputId": "745f96cd-3a53-4cf2-9b86-0e0d9d0dddf6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f8285db49845b69ed7cc52ab35612f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "# tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "# model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBrQeZYv5kUi"
   },
   "outputs": [],
   "source": [
    "tokenized = df['Description'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkYCjmLG5kUt"
   },
   "outputs": [],
   "source": [
    "# max_len = 0\n",
    "\n",
    "# # For every sentence...\n",
    "# for sent in sentences:\n",
    "\n",
    "#     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "#     # Update the maximum sentence length.\n",
    "#     max_len = max(max_len, len(input_ids))\n",
    "\n",
    "# print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "I0-Jide75kU5",
    "outputId": "b71c1513-c286-47a9-9e6b-3ad01ba29564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Right lane blocked due to accident on I-70 Eastbound at Exit 41 OH-235 State Route 4.\n",
      "Token IDs: tensor([  101,  2157,  4644,  8534,  2349,  2000,  4926,  2006,  1045,  1011,\n",
      "         3963, 24773,  2012,  6164,  4601,  2821,  1011, 17825,  2110,  2799,\n",
      "         1018,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SenDmf0G5kVH"
   },
   "outputs": [],
   "source": [
    "labels = df['Severity']\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9lmzQ0HJ5kVR",
    "outputId": "70b162ad-9ee1-4504-f75f-bb1cb6d36e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,676,900 training samples\n",
      "297,434 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_XSK1BR5kVb"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 64\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_qezgIqS5kVo",
    "outputId": "61241b0a-a7a5-41fc-a042-03afc0c068f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "XEDtxJn75kVz",
    "outputId": "d522a5f1-a1df-451b-8477-49a0532f305f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (4, 768)\n",
      "classifier.bias                                                 (4,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOAQRQGT5kV9"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBYIxDjO5kWM"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVW91QgB5kWW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hE9twxMf5kWg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zIXkw7gl5kWv",
    "outputId": "4ced9b6d-ea91-4684-fb28-bd26cbbd6ac9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  41,827.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  41,827.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  41,827.    Elapsed: 0:00:44.\n",
      "  Batch   160  of  41,827.    Elapsed: 0:00:59.\n",
      "  Batch   200  of  41,827.    Elapsed: 0:01:14.\n",
      "  Batch   240  of  41,827.    Elapsed: 0:01:28.\n",
      "  Batch   280  of  41,827.    Elapsed: 0:01:43.\n",
      "  Batch   320  of  41,827.    Elapsed: 0:01:57.\n",
      "  Batch   360  of  41,827.    Elapsed: 0:02:12.\n",
      "  Batch   400  of  41,827.    Elapsed: 0:02:27.\n",
      "  Batch   440  of  41,827.    Elapsed: 0:02:41.\n",
      "  Batch   480  of  41,827.    Elapsed: 0:02:56.\n",
      "  Batch   520  of  41,827.    Elapsed: 0:03:10.\n",
      "  Batch   560  of  41,827.    Elapsed: 0:03:25.\n",
      "  Batch   600  of  41,827.    Elapsed: 0:03:40.\n",
      "  Batch   640  of  41,827.    Elapsed: 0:03:54.\n",
      "  Batch   680  of  41,827.    Elapsed: 0:04:09.\n",
      "  Batch   720  of  41,827.    Elapsed: 0:04:23.\n",
      "  Batch   760  of  41,827.    Elapsed: 0:04:38.\n",
      "  Batch   800  of  41,827.    Elapsed: 0:04:53.\n",
      "  Batch   840  of  41,827.    Elapsed: 0:05:07.\n",
      "  Batch   880  of  41,827.    Elapsed: 0:05:22.\n",
      "  Batch   920  of  41,827.    Elapsed: 0:05:36.\n",
      "  Batch   960  of  41,827.    Elapsed: 0:05:51.\n",
      "  Batch 1,000  of  41,827.    Elapsed: 0:06:06.\n",
      "  Batch 1,040  of  41,827.    Elapsed: 0:06:20.\n",
      "  Batch 1,080  of  41,827.    Elapsed: 0:06:35.\n",
      "  Batch 1,120  of  41,827.    Elapsed: 0:06:49.\n",
      "  Batch 1,160  of  41,827.    Elapsed: 0:07:04.\n",
      "  Batch 1,200  of  41,827.    Elapsed: 0:07:18.\n",
      "  Batch 1,240  of  41,827.    Elapsed: 0:07:33.\n",
      "  Batch 1,280  of  41,827.    Elapsed: 0:07:48.\n",
      "  Batch 1,320  of  41,827.    Elapsed: 0:08:02.\n",
      "  Batch 1,360  of  41,827.    Elapsed: 0:08:17.\n",
      "  Batch 1,400  of  41,827.    Elapsed: 0:08:31.\n",
      "  Batch 1,440  of  41,827.    Elapsed: 0:08:46.\n",
      "  Batch 1,480  of  41,827.    Elapsed: 0:09:00.\n",
      "  Batch 1,520  of  41,827.    Elapsed: 0:09:15.\n",
      "  Batch 1,560  of  41,827.    Elapsed: 0:09:30.\n",
      "  Batch 1,600  of  41,827.    Elapsed: 0:09:44.\n",
      "  Batch 1,640  of  41,827.    Elapsed: 0:09:59.\n",
      "  Batch 1,680  of  41,827.    Elapsed: 0:10:13.\n",
      "  Batch 1,720  of  41,827.    Elapsed: 0:10:28.\n",
      "  Batch 1,760  of  41,827.    Elapsed: 0:10:43.\n",
      "  Batch 1,800  of  41,827.    Elapsed: 0:10:57.\n",
      "  Batch 1,840  of  41,827.    Elapsed: 0:11:12.\n",
      "  Batch 1,880  of  41,827.    Elapsed: 0:11:26.\n",
      "  Batch 1,920  of  41,827.    Elapsed: 0:11:41.\n",
      "  Batch 1,960  of  41,827.    Elapsed: 0:11:55.\n",
      "  Batch 2,000  of  41,827.    Elapsed: 0:12:10.\n",
      "  Batch 2,040  of  41,827.    Elapsed: 0:12:25.\n",
      "  Batch 2,080  of  41,827.    Elapsed: 0:12:39.\n",
      "  Batch 2,120  of  41,827.    Elapsed: 0:12:54.\n",
      "  Batch 2,160  of  41,827.    Elapsed: 0:13:08.\n",
      "  Batch 2,200  of  41,827.    Elapsed: 0:13:23.\n",
      "  Batch 2,240  of  41,827.    Elapsed: 0:13:38.\n",
      "  Batch 2,280  of  41,827.    Elapsed: 0:13:52.\n",
      "  Batch 2,320  of  41,827.    Elapsed: 0:14:07.\n",
      "  Batch 2,360  of  41,827.    Elapsed: 0:14:21.\n",
      "  Batch 2,400  of  41,827.    Elapsed: 0:14:36.\n",
      "  Batch 2,440  of  41,827.    Elapsed: 0:14:51.\n",
      "  Batch 2,480  of  41,827.    Elapsed: 0:15:05.\n",
      "  Batch 2,520  of  41,827.    Elapsed: 0:15:20.\n",
      "  Batch 2,560  of  41,827.    Elapsed: 0:15:34.\n",
      "  Batch 2,600  of  41,827.    Elapsed: 0:15:49.\n",
      "  Batch 2,640  of  41,827.    Elapsed: 0:16:04.\n",
      "  Batch 2,680  of  41,827.    Elapsed: 0:16:18.\n",
      "  Batch 2,720  of  41,827.    Elapsed: 0:16:33.\n",
      "  Batch 2,760  of  41,827.    Elapsed: 0:16:47.\n",
      "  Batch 2,800  of  41,827.    Elapsed: 0:17:02.\n",
      "  Batch 2,840  of  41,827.    Elapsed: 0:17:16.\n",
      "  Batch 2,880  of  41,827.    Elapsed: 0:17:31.\n",
      "  Batch 2,920  of  41,827.    Elapsed: 0:17:46.\n",
      "  Batch 2,960  of  41,827.    Elapsed: 0:18:00.\n",
      "  Batch 3,000  of  41,827.    Elapsed: 0:18:15.\n",
      "  Batch 3,040  of  41,827.    Elapsed: 0:18:30.\n",
      "  Batch 3,080  of  41,827.    Elapsed: 0:18:44.\n",
      "  Batch 3,120  of  41,827.    Elapsed: 0:18:59.\n",
      "  Batch 3,160  of  41,827.    Elapsed: 0:19:13.\n",
      "  Batch 3,200  of  41,827.    Elapsed: 0:19:28.\n",
      "  Batch 3,240  of  41,827.    Elapsed: 0:19:42.\n",
      "  Batch 3,280  of  41,827.    Elapsed: 0:19:57.\n",
      "  Batch 3,320  of  41,827.    Elapsed: 0:20:12.\n",
      "  Batch 3,360  of  41,827.    Elapsed: 0:20:26.\n",
      "  Batch 3,400  of  41,827.    Elapsed: 0:20:41.\n",
      "  Batch 3,440  of  41,827.    Elapsed: 0:20:55.\n",
      "  Batch 3,480  of  41,827.    Elapsed: 0:21:10.\n",
      "  Batch 3,520  of  41,827.    Elapsed: 0:21:25.\n",
      "  Batch 3,560  of  41,827.    Elapsed: 0:21:39.\n",
      "  Batch 3,600  of  41,827.    Elapsed: 0:21:54.\n",
      "  Batch 3,640  of  41,827.    Elapsed: 0:22:08.\n",
      "  Batch 3,680  of  41,827.    Elapsed: 0:22:23.\n",
      "  Batch 3,720  of  41,827.    Elapsed: 0:22:37.\n",
      "  Batch 3,760  of  41,827.    Elapsed: 0:22:52.\n",
      "  Batch 3,800  of  41,827.    Elapsed: 0:23:07.\n",
      "  Batch 3,840  of  41,827.    Elapsed: 0:23:21.\n",
      "  Batch 3,880  of  41,827.    Elapsed: 0:23:36.\n",
      "  Batch 3,920  of  41,827.    Elapsed: 0:23:50.\n",
      "  Batch 3,960  of  41,827.    Elapsed: 0:24:05.\n",
      "  Batch 4,000  of  41,827.    Elapsed: 0:24:19.\n",
      "  Batch 4,040  of  41,827.    Elapsed: 0:24:34.\n",
      "  Batch 4,080  of  41,827.    Elapsed: 0:24:49.\n",
      "  Batch 4,120  of  41,827.    Elapsed: 0:25:03.\n",
      "  Batch 4,160  of  41,827.    Elapsed: 0:25:18.\n",
      "  Batch 4,200  of  41,827.    Elapsed: 0:25:32.\n",
      "  Batch 4,240  of  41,827.    Elapsed: 0:25:47.\n",
      "  Batch 4,280  of  41,827.    Elapsed: 0:26:01.\n",
      "  Batch 4,320  of  41,827.    Elapsed: 0:26:16.\n",
      "  Batch 4,360  of  41,827.    Elapsed: 0:26:31.\n",
      "  Batch 4,400  of  41,827.    Elapsed: 0:26:45.\n",
      "  Batch 4,440  of  41,827.    Elapsed: 0:27:00.\n",
      "  Batch 4,480  of  41,827.    Elapsed: 0:27:14.\n",
      "  Batch 4,520  of  41,827.    Elapsed: 0:27:29.\n",
      "  Batch 4,560  of  41,827.    Elapsed: 0:27:43.\n",
      "  Batch 4,600  of  41,827.    Elapsed: 0:27:58.\n",
      "  Batch 4,640  of  41,827.    Elapsed: 0:28:13.\n",
      "  Batch 4,680  of  41,827.    Elapsed: 0:28:27.\n",
      "  Batch 4,720  of  41,827.    Elapsed: 0:28:42.\n",
      "  Batch 4,760  of  41,827.    Elapsed: 0:28:56.\n",
      "  Batch 4,800  of  41,827.    Elapsed: 0:29:11.\n",
      "  Batch 4,840  of  41,827.    Elapsed: 0:29:25.\n",
      "  Batch 4,880  of  41,827.    Elapsed: 0:29:40.\n",
      "  Batch 4,920  of  41,827.    Elapsed: 0:29:55.\n",
      "  Batch 4,960  of  41,827.    Elapsed: 0:30:09.\n",
      "  Batch 5,000  of  41,827.    Elapsed: 0:30:24.\n",
      "  Batch 5,040  of  41,827.    Elapsed: 0:30:38.\n",
      "  Batch 5,080  of  41,827.    Elapsed: 0:30:53.\n",
      "  Batch 5,120  of  41,827.    Elapsed: 0:31:08.\n",
      "  Batch 5,160  of  41,827.    Elapsed: 0:31:22.\n",
      "  Batch 5,200  of  41,827.    Elapsed: 0:31:37.\n",
      "  Batch 5,240  of  41,827.    Elapsed: 0:31:51.\n",
      "  Batch 5,280  of  41,827.    Elapsed: 0:32:06.\n",
      "  Batch 5,320  of  41,827.    Elapsed: 0:32:20.\n",
      "  Batch 5,360  of  41,827.    Elapsed: 0:32:35.\n",
      "  Batch 5,400  of  41,827.    Elapsed: 0:32:50.\n",
      "  Batch 5,440  of  41,827.    Elapsed: 0:33:04.\n",
      "  Batch 5,480  of  41,827.    Elapsed: 0:33:19.\n",
      "  Batch 5,520  of  41,827.    Elapsed: 0:33:33.\n",
      "  Batch 5,560  of  41,827.    Elapsed: 0:33:48.\n",
      "  Batch 5,600  of  41,827.    Elapsed: 0:34:03.\n",
      "  Batch 5,640  of  41,827.    Elapsed: 0:34:17.\n",
      "  Batch 5,680  of  41,827.    Elapsed: 0:34:32.\n",
      "  Batch 5,720  of  41,827.    Elapsed: 0:34:46.\n",
      "  Batch 5,760  of  41,827.    Elapsed: 0:35:01.\n",
      "  Batch 5,800  of  41,827.    Elapsed: 0:35:15.\n",
      "  Batch 5,840  of  41,827.    Elapsed: 0:35:30.\n",
      "  Batch 5,880  of  41,827.    Elapsed: 0:35:45.\n",
      "  Batch 5,920  of  41,827.    Elapsed: 0:35:59.\n",
      "  Batch 5,960  of  41,827.    Elapsed: 0:36:14.\n",
      "  Batch 6,000  of  41,827.    Elapsed: 0:36:28.\n",
      "  Batch 6,040  of  41,827.    Elapsed: 0:36:43.\n",
      "  Batch 6,080  of  41,827.    Elapsed: 0:36:58.\n",
      "  Batch 6,120  of  41,827.    Elapsed: 0:37:12.\n",
      "  Batch 6,160  of  41,827.    Elapsed: 0:37:27.\n",
      "  Batch 6,200  of  41,827.    Elapsed: 0:37:41.\n",
      "  Batch 6,240  of  41,827.    Elapsed: 0:37:56.\n",
      "  Batch 6,280  of  41,827.    Elapsed: 0:38:10.\n",
      "  Batch 6,320  of  41,827.    Elapsed: 0:38:25.\n",
      "  Batch 6,360  of  41,827.    Elapsed: 0:38:40.\n",
      "  Batch 6,400  of  41,827.    Elapsed: 0:38:54.\n",
      "  Batch 6,440  of  41,827.    Elapsed: 0:39:09.\n",
      "  Batch 6,480  of  41,827.    Elapsed: 0:39:23.\n",
      "  Batch 6,520  of  41,827.    Elapsed: 0:39:38.\n",
      "  Batch 6,560  of  41,827.    Elapsed: 0:39:53.\n",
      "  Batch 6,600  of  41,827.    Elapsed: 0:40:07.\n",
      "  Batch 6,640  of  41,827.    Elapsed: 0:40:22.\n",
      "  Batch 6,680  of  41,827.    Elapsed: 0:40:36.\n",
      "  Batch 6,720  of  41,827.    Elapsed: 0:40:51.\n",
      "  Batch 6,760  of  41,827.    Elapsed: 0:41:05.\n",
      "  Batch 6,800  of  41,827.    Elapsed: 0:41:20.\n",
      "  Batch 6,840  of  41,827.    Elapsed: 0:41:35.\n",
      "  Batch 6,880  of  41,827.    Elapsed: 0:41:49.\n",
      "  Batch 6,920  of  41,827.    Elapsed: 0:42:04.\n",
      "  Batch 6,960  of  41,827.    Elapsed: 0:42:18.\n",
      "  Batch 7,000  of  41,827.    Elapsed: 0:42:33.\n",
      "  Batch 7,040  of  41,827.    Elapsed: 0:42:48.\n",
      "  Batch 7,080  of  41,827.    Elapsed: 0:43:02.\n",
      "  Batch 7,120  of  41,827.    Elapsed: 0:43:17.\n",
      "  Batch 7,160  of  41,827.    Elapsed: 0:43:31.\n",
      "  Batch 7,200  of  41,827.    Elapsed: 0:43:46.\n",
      "  Batch 7,240  of  41,827.    Elapsed: 0:44:00.\n",
      "  Batch 7,280  of  41,827.    Elapsed: 0:44:15.\n",
      "  Batch 7,320  of  41,827.    Elapsed: 0:44:30.\n",
      "  Batch 7,360  of  41,827.    Elapsed: 0:44:44.\n",
      "  Batch 7,400  of  41,827.    Elapsed: 0:44:59.\n",
      "  Batch 7,440  of  41,827.    Elapsed: 0:45:13.\n",
      "  Batch 7,480  of  41,827.    Elapsed: 0:45:28.\n",
      "  Batch 7,520  of  41,827.    Elapsed: 0:45:43.\n",
      "  Batch 7,560  of  41,827.    Elapsed: 0:45:57.\n",
      "  Batch 7,600  of  41,827.    Elapsed: 0:46:12.\n",
      "  Batch 7,640  of  41,827.    Elapsed: 0:46:26.\n",
      "  Batch 7,680  of  41,827.    Elapsed: 0:46:41.\n",
      "  Batch 7,720  of  41,827.    Elapsed: 0:46:55.\n",
      "  Batch 7,760  of  41,827.    Elapsed: 0:47:10.\n",
      "  Batch 7,800  of  41,827.    Elapsed: 0:47:25.\n",
      "  Batch 7,840  of  41,827.    Elapsed: 0:47:39.\n",
      "  Batch 7,880  of  41,827.    Elapsed: 0:47:54.\n",
      "  Batch 7,920  of  41,827.    Elapsed: 0:48:08.\n",
      "  Batch 7,960  of  41,827.    Elapsed: 0:48:23.\n",
      "  Batch 8,000  of  41,827.    Elapsed: 0:48:37.\n",
      "  Batch 8,040  of  41,827.    Elapsed: 0:48:52.\n",
      "  Batch 8,080  of  41,827.    Elapsed: 0:49:07.\n",
      "  Batch 8,120  of  41,827.    Elapsed: 0:49:21.\n",
      "  Batch 8,160  of  41,827.    Elapsed: 0:49:36.\n",
      "  Batch 8,200  of  41,827.    Elapsed: 0:49:50.\n",
      "  Batch 8,240  of  41,827.    Elapsed: 0:50:05.\n",
      "  Batch 8,280  of  41,827.    Elapsed: 0:50:20.\n",
      "  Batch 8,320  of  41,827.    Elapsed: 0:50:34.\n",
      "  Batch 8,360  of  41,827.    Elapsed: 0:50:49.\n",
      "  Batch 8,400  of  41,827.    Elapsed: 0:51:03.\n",
      "  Batch 8,440  of  41,827.    Elapsed: 0:51:18.\n",
      "  Batch 8,480  of  41,827.    Elapsed: 0:51:32.\n",
      "  Batch 8,520  of  41,827.    Elapsed: 0:51:47.\n",
      "  Batch 8,560  of  41,827.    Elapsed: 0:52:02.\n",
      "  Batch 8,600  of  41,827.    Elapsed: 0:52:16.\n",
      "  Batch 8,640  of  41,827.    Elapsed: 0:52:31.\n",
      "  Batch 8,680  of  41,827.    Elapsed: 0:52:45.\n",
      "  Batch 8,720  of  41,827.    Elapsed: 0:53:00.\n",
      "  Batch 8,760  of  41,827.    Elapsed: 0:53:14.\n",
      "  Batch 8,800  of  41,827.    Elapsed: 0:53:29.\n",
      "  Batch 8,840  of  41,827.    Elapsed: 0:53:44.\n",
      "  Batch 8,880  of  41,827.    Elapsed: 0:53:58.\n",
      "  Batch 8,920  of  41,827.    Elapsed: 0:54:13.\n",
      "  Batch 8,960  of  41,827.    Elapsed: 0:54:27.\n",
      "  Batch 9,000  of  41,827.    Elapsed: 0:54:42.\n",
      "  Batch 9,040  of  41,827.    Elapsed: 0:54:56.\n",
      "  Batch 9,080  of  41,827.    Elapsed: 0:55:11.\n",
      "  Batch 9,120  of  41,827.    Elapsed: 0:55:26.\n",
      "  Batch 9,160  of  41,827.    Elapsed: 0:55:40.\n",
      "  Batch 9,200  of  41,827.    Elapsed: 0:55:55.\n",
      "  Batch 9,240  of  41,827.    Elapsed: 0:56:09.\n",
      "  Batch 9,280  of  41,827.    Elapsed: 0:56:24.\n",
      "  Batch 9,320  of  41,827.    Elapsed: 0:56:38.\n",
      "  Batch 9,360  of  41,827.    Elapsed: 0:56:53.\n",
      "  Batch 9,400  of  41,827.    Elapsed: 0:57:08.\n",
      "  Batch 9,440  of  41,827.    Elapsed: 0:57:22.\n",
      "  Batch 9,480  of  41,827.    Elapsed: 0:57:37.\n",
      "  Batch 9,520  of  41,827.    Elapsed: 0:57:51.\n",
      "  Batch 9,560  of  41,827.    Elapsed: 0:58:06.\n",
      "  Batch 9,600  of  41,827.    Elapsed: 0:58:20.\n",
      "  Batch 9,640  of  41,827.    Elapsed: 0:58:35.\n",
      "  Batch 9,680  of  41,827.    Elapsed: 0:58:50.\n",
      "  Batch 9,720  of  41,827.    Elapsed: 0:59:04.\n",
      "  Batch 9,760  of  41,827.    Elapsed: 0:59:19.\n",
      "  Batch 9,800  of  41,827.    Elapsed: 0:59:33.\n",
      "  Batch 9,840  of  41,827.    Elapsed: 0:59:48.\n",
      "  Batch 9,880  of  41,827.    Elapsed: 1:00:02.\n",
      "  Batch 9,920  of  41,827.    Elapsed: 1:00:17.\n",
      "  Batch 9,960  of  41,827.    Elapsed: 1:00:32.\n",
      "  Batch 10,000  of  41,827.    Elapsed: 1:00:46.\n",
      "  Batch 10,040  of  41,827.    Elapsed: 1:01:01.\n",
      "  Batch 10,080  of  41,827.    Elapsed: 1:01:15.\n",
      "  Batch 10,120  of  41,827.    Elapsed: 1:01:30.\n",
      "  Batch 10,160  of  41,827.    Elapsed: 1:01:44.\n",
      "  Batch 10,200  of  41,827.    Elapsed: 1:01:59.\n",
      "  Batch 10,240  of  41,827.    Elapsed: 1:02:13.\n",
      "  Batch 10,280  of  41,827.    Elapsed: 1:02:28.\n",
      "  Batch 10,320  of  41,827.    Elapsed: 1:02:43.\n",
      "  Batch 10,360  of  41,827.    Elapsed: 1:02:57.\n",
      "  Batch 10,400  of  41,827.    Elapsed: 1:03:12.\n",
      "  Batch 10,440  of  41,827.    Elapsed: 1:03:26.\n",
      "  Batch 10,480  of  41,827.    Elapsed: 1:03:41.\n",
      "  Batch 10,520  of  41,827.    Elapsed: 1:03:55.\n",
      "  Batch 10,560  of  41,827.    Elapsed: 1:04:10.\n",
      "  Batch 10,600  of  41,827.    Elapsed: 1:04:25.\n",
      "  Batch 10,640  of  41,827.    Elapsed: 1:04:39.\n",
      "  Batch 10,680  of  41,827.    Elapsed: 1:04:54.\n",
      "  Batch 10,720  of  41,827.    Elapsed: 1:05:08.\n",
      "  Batch 10,760  of  41,827.    Elapsed: 1:05:23.\n",
      "  Batch 10,800  of  41,827.    Elapsed: 1:05:37.\n",
      "  Batch 10,840  of  41,827.    Elapsed: 1:05:52.\n",
      "  Batch 10,880  of  41,827.    Elapsed: 1:06:07.\n",
      "  Batch 10,920  of  41,827.    Elapsed: 1:06:21.\n",
      "  Batch 10,960  of  41,827.    Elapsed: 1:06:36.\n",
      "  Batch 11,000  of  41,827.    Elapsed: 1:06:50.\n",
      "  Batch 11,040  of  41,827.    Elapsed: 1:07:05.\n",
      "  Batch 11,080  of  41,827.    Elapsed: 1:07:19.\n",
      "  Batch 11,120  of  41,827.    Elapsed: 1:07:34.\n",
      "  Batch 11,160  of  41,827.    Elapsed: 1:07:49.\n",
      "  Batch 11,200  of  41,827.    Elapsed: 1:08:03.\n",
      "  Batch 11,240  of  41,827.    Elapsed: 1:08:18.\n",
      "  Batch 11,280  of  41,827.    Elapsed: 1:08:32.\n",
      "  Batch 11,320  of  41,827.    Elapsed: 1:08:47.\n",
      "  Batch 11,360  of  41,827.    Elapsed: 1:09:01.\n",
      "  Batch 11,400  of  41,827.    Elapsed: 1:09:16.\n",
      "  Batch 11,440  of  41,827.    Elapsed: 1:09:31.\n",
      "  Batch 11,480  of  41,827.    Elapsed: 1:09:45.\n",
      "  Batch 11,520  of  41,827.    Elapsed: 1:10:00.\n",
      "  Batch 11,560  of  41,827.    Elapsed: 1:10:14.\n",
      "  Batch 11,600  of  41,827.    Elapsed: 1:10:29.\n",
      "  Batch 11,640  of  41,827.    Elapsed: 1:10:43.\n",
      "  Batch 11,680  of  41,827.    Elapsed: 1:10:58.\n",
      "  Batch 11,720  of  41,827.    Elapsed: 1:11:12.\n",
      "  Batch 11,760  of  41,827.    Elapsed: 1:11:27.\n",
      "  Batch 11,800  of  41,827.    Elapsed: 1:11:42.\n",
      "  Batch 11,840  of  41,827.    Elapsed: 1:11:56.\n",
      "  Batch 11,880  of  41,827.    Elapsed: 1:12:11.\n",
      "  Batch 11,920  of  41,827.    Elapsed: 1:12:25.\n",
      "  Batch 11,960  of  41,827.    Elapsed: 1:12:40.\n",
      "  Batch 12,000  of  41,827.    Elapsed: 1:12:55.\n",
      "  Batch 12,040  of  41,827.    Elapsed: 1:13:09.\n",
      "  Batch 12,080  of  41,827.    Elapsed: 1:13:24.\n",
      "  Batch 12,120  of  41,827.    Elapsed: 1:13:38.\n",
      "  Batch 12,160  of  41,827.    Elapsed: 1:13:53.\n",
      "  Batch 12,200  of  41,827.    Elapsed: 1:14:07.\n",
      "  Batch 12,240  of  41,827.    Elapsed: 1:14:22.\n",
      "  Batch 12,280  of  41,827.    Elapsed: 1:14:37.\n",
      "  Batch 12,320  of  41,827.    Elapsed: 1:14:51.\n",
      "  Batch 12,360  of  41,827.    Elapsed: 1:15:06.\n",
      "  Batch 12,400  of  41,827.    Elapsed: 1:15:20.\n",
      "  Batch 12,440  of  41,827.    Elapsed: 1:15:35.\n",
      "  Batch 12,480  of  41,827.    Elapsed: 1:15:50.\n",
      "  Batch 12,520  of  41,827.    Elapsed: 1:16:04.\n",
      "  Batch 12,560  of  41,827.    Elapsed: 1:16:19.\n",
      "  Batch 12,600  of  41,827.    Elapsed: 1:16:33.\n",
      "  Batch 12,640  of  41,827.    Elapsed: 1:16:48.\n",
      "  Batch 12,680  of  41,827.    Elapsed: 1:17:02.\n",
      "  Batch 12,720  of  41,827.    Elapsed: 1:17:17.\n",
      "  Batch 12,760  of  41,827.    Elapsed: 1:17:31.\n",
      "  Batch 12,800  of  41,827.    Elapsed: 1:17:46.\n",
      "  Batch 12,840  of  41,827.    Elapsed: 1:18:01.\n",
      "  Batch 12,880  of  41,827.    Elapsed: 1:18:15.\n",
      "  Batch 12,920  of  41,827.    Elapsed: 1:18:30.\n",
      "  Batch 12,960  of  41,827.    Elapsed: 1:18:44.\n",
      "  Batch 13,000  of  41,827.    Elapsed: 1:18:59.\n",
      "  Batch 13,040  of  41,827.    Elapsed: 1:19:13.\n",
      "  Batch 13,080  of  41,827.    Elapsed: 1:19:28.\n",
      "  Batch 13,120  of  41,827.    Elapsed: 1:19:43.\n",
      "  Batch 13,160  of  41,827.    Elapsed: 1:19:57.\n",
      "  Batch 13,200  of  41,827.    Elapsed: 1:20:12.\n",
      "  Batch 13,240  of  41,827.    Elapsed: 1:20:26.\n",
      "  Batch 13,280  of  41,827.    Elapsed: 1:20:41.\n",
      "  Batch 13,320  of  41,827.    Elapsed: 1:20:55.\n",
      "  Batch 13,360  of  41,827.    Elapsed: 1:21:10.\n",
      "  Batch 13,400  of  41,827.    Elapsed: 1:21:25.\n",
      "  Batch 13,440  of  41,827.    Elapsed: 1:21:39.\n",
      "  Batch 13,480  of  41,827.    Elapsed: 1:21:54.\n",
      "  Batch 13,520  of  41,827.    Elapsed: 1:22:08.\n",
      "  Batch 13,560  of  41,827.    Elapsed: 1:22:23.\n",
      "  Batch 13,600  of  41,827.    Elapsed: 1:22:37.\n",
      "  Batch 13,640  of  41,827.    Elapsed: 1:22:52.\n",
      "  Batch 13,680  of  41,827.    Elapsed: 1:23:07.\n",
      "  Batch 13,720  of  41,827.    Elapsed: 1:23:21.\n",
      "  Batch 13,760  of  41,827.    Elapsed: 1:23:36.\n",
      "  Batch 13,800  of  41,827.    Elapsed: 1:23:50.\n",
      "  Batch 13,840  of  41,827.    Elapsed: 1:24:05.\n",
      "  Batch 13,880  of  41,827.    Elapsed: 1:24:19.\n",
      "  Batch 13,920  of  41,827.    Elapsed: 1:24:34.\n",
      "  Batch 13,960  of  41,827.    Elapsed: 1:24:49.\n",
      "  Batch 14,000  of  41,827.    Elapsed: 1:25:03.\n",
      "  Batch 14,040  of  41,827.    Elapsed: 1:25:18.\n",
      "  Batch 14,080  of  41,827.    Elapsed: 1:25:32.\n",
      "  Batch 14,120  of  41,827.    Elapsed: 1:25:47.\n",
      "  Batch 14,160  of  41,827.    Elapsed: 1:26:01.\n",
      "  Batch 14,200  of  41,827.    Elapsed: 1:26:16.\n",
      "  Batch 14,240  of  41,827.    Elapsed: 1:26:31.\n",
      "  Batch 14,280  of  41,827.    Elapsed: 1:26:45.\n",
      "  Batch 14,320  of  41,827.    Elapsed: 1:27:00.\n",
      "  Batch 14,360  of  41,827.    Elapsed: 1:27:14.\n",
      "  Batch 14,400  of  41,827.    Elapsed: 1:27:29.\n",
      "  Batch 14,440  of  41,827.    Elapsed: 1:27:43.\n",
      "  Batch 14,480  of  41,827.    Elapsed: 1:27:58.\n",
      "  Batch 14,520  of  41,827.    Elapsed: 1:28:12.\n",
      "  Batch 14,560  of  41,827.    Elapsed: 1:28:27.\n",
      "  Batch 14,600  of  41,827.    Elapsed: 1:28:42.\n",
      "  Batch 14,640  of  41,827.    Elapsed: 1:28:56.\n",
      "  Batch 14,680  of  41,827.    Elapsed: 1:29:11.\n",
      "  Batch 14,720  of  41,827.    Elapsed: 1:29:25.\n",
      "  Batch 14,760  of  41,827.    Elapsed: 1:29:40.\n",
      "  Batch 14,800  of  41,827.    Elapsed: 1:29:54.\n",
      "  Batch 14,840  of  41,827.    Elapsed: 1:30:09.\n",
      "  Batch 14,880  of  41,827.    Elapsed: 1:30:24.\n",
      "  Batch 14,920  of  41,827.    Elapsed: 1:30:38.\n",
      "  Batch 14,960  of  41,827.    Elapsed: 1:30:53.\n",
      "  Batch 15,000  of  41,827.    Elapsed: 1:31:07.\n",
      "  Batch 15,040  of  41,827.    Elapsed: 1:31:22.\n",
      "  Batch 15,080  of  41,827.    Elapsed: 1:31:36.\n",
      "  Batch 15,120  of  41,827.    Elapsed: 1:31:51.\n",
      "  Batch 15,160  of  41,827.    Elapsed: 1:32:06.\n",
      "  Batch 15,200  of  41,827.    Elapsed: 1:32:20.\n",
      "  Batch 15,240  of  41,827.    Elapsed: 1:32:35.\n",
      "  Batch 15,280  of  41,827.    Elapsed: 1:32:49.\n",
      "  Batch 15,320  of  41,827.    Elapsed: 1:33:04.\n",
      "  Batch 15,360  of  41,827.    Elapsed: 1:33:18.\n",
      "  Batch 15,400  of  41,827.    Elapsed: 1:33:33.\n",
      "  Batch 15,440  of  41,827.    Elapsed: 1:33:48.\n",
      "  Batch 15,480  of  41,827.    Elapsed: 1:34:02.\n",
      "  Batch 15,520  of  41,827.    Elapsed: 1:34:17.\n",
      "  Batch 15,560  of  41,827.    Elapsed: 1:34:31.\n",
      "  Batch 15,600  of  41,827.    Elapsed: 1:34:46.\n",
      "  Batch 15,640  of  41,827.    Elapsed: 1:35:00.\n",
      "  Batch 15,680  of  41,827.    Elapsed: 1:35:15.\n",
      "  Batch 15,720  of  41,827.    Elapsed: 1:35:30.\n",
      "  Batch 15,760  of  41,827.    Elapsed: 1:35:44.\n",
      "  Batch 15,800  of  41,827.    Elapsed: 1:35:59.\n",
      "  Batch 15,840  of  41,827.    Elapsed: 1:36:13.\n",
      "  Batch 15,880  of  41,827.    Elapsed: 1:36:28.\n",
      "  Batch 15,920  of  41,827.    Elapsed: 1:36:42.\n",
      "  Batch 15,960  of  41,827.    Elapsed: 1:36:57.\n",
      "  Batch 16,000  of  41,827.    Elapsed: 1:37:12.\n",
      "  Batch 16,040  of  41,827.    Elapsed: 1:37:26.\n",
      "  Batch 16,080  of  41,827.    Elapsed: 1:37:41.\n",
      "  Batch 16,120  of  41,827.    Elapsed: 1:37:55.\n",
      "  Batch 16,160  of  41,827.    Elapsed: 1:38:10.\n",
      "  Batch 16,200  of  41,827.    Elapsed: 1:38:24.\n",
      "  Batch 16,240  of  41,827.    Elapsed: 1:38:39.\n",
      "  Batch 16,280  of  41,827.    Elapsed: 1:38:53.\n",
      "  Batch 16,320  of  41,827.    Elapsed: 1:39:08.\n",
      "  Batch 16,360  of  41,827.    Elapsed: 1:39:23.\n",
      "  Batch 16,400  of  41,827.    Elapsed: 1:39:37.\n",
      "  Batch 16,440  of  41,827.    Elapsed: 1:39:52.\n",
      "  Batch 16,480  of  41,827.    Elapsed: 1:40:06.\n",
      "  Batch 16,520  of  41,827.    Elapsed: 1:40:21.\n",
      "  Batch 16,560  of  41,827.    Elapsed: 1:40:36.\n",
      "  Batch 16,600  of  41,827.    Elapsed: 1:40:50.\n",
      "  Batch 16,640  of  41,827.    Elapsed: 1:41:05.\n",
      "  Batch 16,680  of  41,827.    Elapsed: 1:41:19.\n",
      "  Batch 16,720  of  41,827.    Elapsed: 1:41:34.\n",
      "  Batch 16,760  of  41,827.    Elapsed: 1:41:49.\n",
      "  Batch 16,800  of  41,827.    Elapsed: 1:42:03.\n",
      "  Batch 16,840  of  41,827.    Elapsed: 1:42:18.\n",
      "  Batch 16,880  of  41,827.    Elapsed: 1:42:32.\n",
      "  Batch 16,920  of  41,827.    Elapsed: 1:42:47.\n",
      "  Batch 16,960  of  41,827.    Elapsed: 1:43:02.\n",
      "  Batch 17,000  of  41,827.    Elapsed: 1:43:16.\n",
      "  Batch 17,040  of  41,827.    Elapsed: 1:43:31.\n",
      "  Batch 17,080  of  41,827.    Elapsed: 1:43:45.\n",
      "  Batch 17,120  of  41,827.    Elapsed: 1:44:00.\n",
      "  Batch 17,160  of  41,827.    Elapsed: 1:44:15.\n",
      "  Batch 17,200  of  41,827.    Elapsed: 1:44:29.\n",
      "  Batch 17,240  of  41,827.    Elapsed: 1:44:44.\n",
      "  Batch 17,280  of  41,827.    Elapsed: 1:44:58.\n",
      "  Batch 17,320  of  41,827.    Elapsed: 1:45:13.\n",
      "  Batch 17,360  of  41,827.    Elapsed: 1:45:28.\n",
      "  Batch 17,400  of  41,827.    Elapsed: 1:45:42.\n",
      "  Batch 17,440  of  41,827.    Elapsed: 1:45:57.\n",
      "  Batch 17,480  of  41,827.    Elapsed: 1:46:12.\n",
      "  Batch 17,520  of  41,827.    Elapsed: 1:46:26.\n",
      "  Batch 17,560  of  41,827.    Elapsed: 1:46:41.\n",
      "  Batch 17,600  of  41,827.    Elapsed: 1:46:55.\n",
      "  Batch 17,640  of  41,827.    Elapsed: 1:47:10.\n",
      "  Batch 17,680  of  41,827.    Elapsed: 1:47:25.\n",
      "  Batch 17,720  of  41,827.    Elapsed: 1:47:39.\n",
      "  Batch 17,760  of  41,827.    Elapsed: 1:47:54.\n",
      "  Batch 17,800  of  41,827.    Elapsed: 1:48:08.\n",
      "  Batch 17,840  of  41,827.    Elapsed: 1:48:23.\n",
      "  Batch 17,880  of  41,827.    Elapsed: 1:48:38.\n",
      "  Batch 17,920  of  41,827.    Elapsed: 1:48:52.\n",
      "  Batch 17,960  of  41,827.    Elapsed: 1:49:07.\n",
      "  Batch 18,000  of  41,827.    Elapsed: 1:49:21.\n",
      "  Batch 18,040  of  41,827.    Elapsed: 1:49:36.\n",
      "  Batch 18,080  of  41,827.    Elapsed: 1:49:51.\n",
      "  Batch 18,120  of  41,827.    Elapsed: 1:50:05.\n",
      "  Batch 18,160  of  41,827.    Elapsed: 1:50:20.\n",
      "  Batch 18,200  of  41,827.    Elapsed: 1:50:34.\n",
      "  Batch 18,240  of  41,827.    Elapsed: 1:50:49.\n",
      "  Batch 18,280  of  41,827.    Elapsed: 1:51:04.\n",
      "  Batch 18,320  of  41,827.    Elapsed: 1:51:18.\n",
      "  Batch 18,360  of  41,827.    Elapsed: 1:51:33.\n",
      "  Batch 18,400  of  41,827.    Elapsed: 1:51:47.\n",
      "  Batch 18,440  of  41,827.    Elapsed: 1:52:02.\n",
      "  Batch 18,480  of  41,827.    Elapsed: 1:52:17.\n",
      "  Batch 18,520  of  41,827.    Elapsed: 1:52:31.\n",
      "  Batch 18,560  of  41,827.    Elapsed: 1:52:46.\n",
      "  Batch 18,600  of  41,827.    Elapsed: 1:53:01.\n",
      "  Batch 18,640  of  41,827.    Elapsed: 1:53:15.\n",
      "  Batch 18,680  of  41,827.    Elapsed: 1:53:30.\n",
      "  Batch 18,720  of  41,827.    Elapsed: 1:53:44.\n",
      "  Batch 18,760  of  41,827.    Elapsed: 1:53:59.\n",
      "  Batch 18,800  of  41,827.    Elapsed: 1:54:14.\n",
      "  Batch 18,840  of  41,827.    Elapsed: 1:54:28.\n",
      "  Batch 18,880  of  41,827.    Elapsed: 1:54:43.\n",
      "  Batch 18,920  of  41,827.    Elapsed: 1:54:57.\n",
      "  Batch 18,960  of  41,827.    Elapsed: 1:55:12.\n",
      "  Batch 19,000  of  41,827.    Elapsed: 1:55:27.\n",
      "  Batch 19,040  of  41,827.    Elapsed: 1:55:41.\n",
      "  Batch 19,080  of  41,827.    Elapsed: 1:55:56.\n",
      "  Batch 19,120  of  41,827.    Elapsed: 1:56:11.\n",
      "  Batch 19,160  of  41,827.    Elapsed: 1:56:25.\n",
      "  Batch 19,200  of  41,827.    Elapsed: 1:56:40.\n",
      "  Batch 19,240  of  41,827.    Elapsed: 1:56:54.\n",
      "  Batch 19,280  of  41,827.    Elapsed: 1:57:09.\n",
      "  Batch 19,320  of  41,827.    Elapsed: 1:57:23.\n",
      "  Batch 19,360  of  41,827.    Elapsed: 1:57:38.\n",
      "  Batch 19,400  of  41,827.    Elapsed: 1:57:53.\n",
      "  Batch 19,440  of  41,827.    Elapsed: 1:58:07.\n",
      "  Batch 19,480  of  41,827.    Elapsed: 1:58:22.\n",
      "  Batch 19,520  of  41,827.    Elapsed: 1:58:36.\n",
      "  Batch 19,560  of  41,827.    Elapsed: 1:58:51.\n",
      "  Batch 19,600  of  41,827.    Elapsed: 1:59:06.\n",
      "  Batch 19,640  of  41,827.    Elapsed: 1:59:20.\n",
      "  Batch 19,680  of  41,827.    Elapsed: 1:59:35.\n",
      "  Batch 19,720  of  41,827.    Elapsed: 1:59:50.\n",
      "  Batch 19,760  of  41,827.    Elapsed: 2:00:04.\n",
      "  Batch 19,800  of  41,827.    Elapsed: 2:00:19.\n",
      "  Batch 19,840  of  41,827.    Elapsed: 2:00:33.\n",
      "  Batch 19,880  of  41,827.    Elapsed: 2:00:48.\n",
      "  Batch 19,920  of  41,827.    Elapsed: 2:01:03.\n",
      "  Batch 19,960  of  41,827.    Elapsed: 2:01:17.\n",
      "  Batch 20,000  of  41,827.    Elapsed: 2:01:32.\n",
      "  Batch 20,040  of  41,827.    Elapsed: 2:01:46.\n",
      "  Batch 20,080  of  41,827.    Elapsed: 2:02:01.\n",
      "  Batch 20,120  of  41,827.    Elapsed: 2:02:16.\n",
      "  Batch 20,160  of  41,827.    Elapsed: 2:02:30.\n",
      "  Batch 20,200  of  41,827.    Elapsed: 2:02:45.\n",
      "  Batch 20,240  of  41,827.    Elapsed: 2:02:59.\n",
      "  Batch 20,280  of  41,827.    Elapsed: 2:03:14.\n",
      "  Batch 20,320  of  41,827.    Elapsed: 2:03:28.\n",
      "  Batch 20,360  of  41,827.    Elapsed: 2:03:43.\n",
      "  Batch 20,400  of  41,827.    Elapsed: 2:03:58.\n",
      "  Batch 20,440  of  41,827.    Elapsed: 2:04:12.\n",
      "  Batch 20,480  of  41,827.    Elapsed: 2:04:27.\n",
      "  Batch 20,520  of  41,827.    Elapsed: 2:04:41.\n",
      "  Batch 20,560  of  41,827.    Elapsed: 2:04:56.\n",
      "  Batch 20,600  of  41,827.    Elapsed: 2:05:10.\n",
      "  Batch 20,640  of  41,827.    Elapsed: 2:05:25.\n",
      "  Batch 20,680  of  41,827.    Elapsed: 2:05:40.\n",
      "  Batch 20,720  of  41,827.    Elapsed: 2:05:54.\n",
      "  Batch 20,760  of  41,827.    Elapsed: 2:06:09.\n",
      "  Batch 20,800  of  41,827.    Elapsed: 2:06:23.\n",
      "  Batch 20,840  of  41,827.    Elapsed: 2:06:38.\n",
      "  Batch 20,880  of  41,827.    Elapsed: 2:06:53.\n",
      "  Batch 20,920  of  41,827.    Elapsed: 2:07:07.\n",
      "  Batch 20,960  of  41,827.    Elapsed: 2:07:22.\n",
      "  Batch 21,000  of  41,827.    Elapsed: 2:07:36.\n",
      "  Batch 21,040  of  41,827.    Elapsed: 2:07:51.\n",
      "  Batch 21,080  of  41,827.    Elapsed: 2:08:06.\n",
      "  Batch 21,120  of  41,827.    Elapsed: 2:08:20.\n",
      "  Batch 21,160  of  41,827.    Elapsed: 2:08:35.\n",
      "  Batch 21,200  of  41,827.    Elapsed: 2:08:49.\n",
      "  Batch 21,240  of  41,827.    Elapsed: 2:09:04.\n",
      "  Batch 21,280  of  41,827.    Elapsed: 2:09:19.\n",
      "  Batch 21,320  of  41,827.    Elapsed: 2:09:33.\n",
      "  Batch 21,360  of  41,827.    Elapsed: 2:09:48.\n",
      "  Batch 21,400  of  41,827.    Elapsed: 2:10:02.\n",
      "  Batch 21,440  of  41,827.    Elapsed: 2:10:17.\n",
      "  Batch 21,480  of  41,827.    Elapsed: 2:10:32.\n",
      "  Batch 21,520  of  41,827.    Elapsed: 2:10:46.\n",
      "  Batch 21,560  of  41,827.    Elapsed: 2:11:01.\n",
      "  Batch 21,600  of  41,827.    Elapsed: 2:11:16.\n",
      "  Batch 21,640  of  41,827.    Elapsed: 2:11:30.\n",
      "  Batch 21,680  of  41,827.    Elapsed: 2:11:45.\n",
      "  Batch 21,720  of  41,827.    Elapsed: 2:11:59.\n",
      "  Batch 21,760  of  41,827.    Elapsed: 2:12:14.\n",
      "  Batch 21,800  of  41,827.    Elapsed: 2:12:29.\n",
      "  Batch 21,840  of  41,827.    Elapsed: 2:12:43.\n",
      "  Batch 21,880  of  41,827.    Elapsed: 2:12:58.\n",
      "  Batch 21,920  of  41,827.    Elapsed: 2:13:13.\n",
      "  Batch 21,960  of  41,827.    Elapsed: 2:13:27.\n",
      "  Batch 22,000  of  41,827.    Elapsed: 2:13:42.\n",
      "  Batch 22,040  of  41,827.    Elapsed: 2:13:57.\n",
      "  Batch 22,080  of  41,827.    Elapsed: 2:14:11.\n",
      "  Batch 22,120  of  41,827.    Elapsed: 2:14:26.\n",
      "  Batch 22,160  of  41,827.    Elapsed: 2:14:40.\n",
      "  Batch 22,200  of  41,827.    Elapsed: 2:14:55.\n",
      "  Batch 22,240  of  41,827.    Elapsed: 2:15:10.\n",
      "  Batch 22,280  of  41,827.    Elapsed: 2:15:24.\n",
      "  Batch 22,320  of  41,827.    Elapsed: 2:15:39.\n",
      "  Batch 22,360  of  41,827.    Elapsed: 2:15:54.\n",
      "  Batch 22,400  of  41,827.    Elapsed: 2:16:08.\n",
      "  Batch 22,440  of  41,827.    Elapsed: 2:16:23.\n",
      "  Batch 22,480  of  41,827.    Elapsed: 2:16:37.\n",
      "  Batch 22,520  of  41,827.    Elapsed: 2:16:52.\n",
      "  Batch 22,560  of  41,827.    Elapsed: 2:17:07.\n",
      "  Batch 22,600  of  41,827.    Elapsed: 2:17:21.\n",
      "  Batch 22,640  of  41,827.    Elapsed: 2:17:36.\n",
      "  Batch 22,680  of  41,827.    Elapsed: 2:17:50.\n",
      "  Batch 22,720  of  41,827.    Elapsed: 2:18:05.\n",
      "  Batch 22,760  of  41,827.    Elapsed: 2:18:20.\n",
      "  Batch 22,800  of  41,827.    Elapsed: 2:18:34.\n",
      "  Batch 22,840  of  41,827.    Elapsed: 2:18:49.\n",
      "  Batch 22,880  of  41,827.    Elapsed: 2:19:04.\n",
      "  Batch 22,920  of  41,827.    Elapsed: 2:19:18.\n",
      "  Batch 22,960  of  41,827.    Elapsed: 2:19:33.\n",
      "  Batch 23,000  of  41,827.    Elapsed: 2:19:48.\n",
      "  Batch 23,040  of  41,827.    Elapsed: 2:20:02.\n",
      "  Batch 23,080  of  41,827.    Elapsed: 2:20:17.\n",
      "  Batch 23,120  of  41,827.    Elapsed: 2:20:31.\n",
      "  Batch 23,160  of  41,827.    Elapsed: 2:20:46.\n",
      "  Batch 23,200  of  41,827.    Elapsed: 2:21:01.\n",
      "  Batch 23,240  of  41,827.    Elapsed: 2:21:15.\n",
      "  Batch 23,280  of  41,827.    Elapsed: 2:21:30.\n",
      "  Batch 23,320  of  41,827.    Elapsed: 2:21:44.\n",
      "  Batch 23,360  of  41,827.    Elapsed: 2:21:59.\n",
      "  Batch 23,400  of  41,827.    Elapsed: 2:22:14.\n",
      "  Batch 23,440  of  41,827.    Elapsed: 2:22:28.\n",
      "  Batch 23,480  of  41,827.    Elapsed: 2:22:43.\n",
      "  Batch 23,520  of  41,827.    Elapsed: 2:22:58.\n",
      "  Batch 23,560  of  41,827.    Elapsed: 2:23:12.\n",
      "  Batch 23,600  of  41,827.    Elapsed: 2:23:27.\n",
      "  Batch 23,640  of  41,827.    Elapsed: 2:23:41.\n",
      "  Batch 23,680  of  41,827.    Elapsed: 2:23:56.\n",
      "  Batch 23,720  of  41,827.    Elapsed: 2:24:11.\n",
      "  Batch 23,760  of  41,827.    Elapsed: 2:24:25.\n",
      "  Batch 23,800  of  41,827.    Elapsed: 2:24:40.\n",
      "  Batch 23,840  of  41,827.    Elapsed: 2:24:54.\n",
      "  Batch 23,880  of  41,827.    Elapsed: 2:25:09.\n",
      "  Batch 23,920  of  41,827.    Elapsed: 2:25:24.\n",
      "  Batch 23,960  of  41,827.    Elapsed: 2:25:38.\n",
      "  Batch 24,000  of  41,827.    Elapsed: 2:25:53.\n",
      "  Batch 24,040  of  41,827.    Elapsed: 2:26:08.\n",
      "  Batch 24,080  of  41,827.    Elapsed: 2:26:22.\n",
      "  Batch 24,120  of  41,827.    Elapsed: 2:26:37.\n",
      "  Batch 24,160  of  41,827.    Elapsed: 2:26:51.\n",
      "  Batch 24,200  of  41,827.    Elapsed: 2:27:06.\n",
      "  Batch 24,240  of  41,827.    Elapsed: 2:27:21.\n",
      "  Batch 24,280  of  41,827.    Elapsed: 2:27:35.\n",
      "  Batch 24,320  of  41,827.    Elapsed: 2:27:50.\n",
      "  Batch 24,360  of  41,827.    Elapsed: 2:28:04.\n",
      "  Batch 24,400  of  41,827.    Elapsed: 2:28:19.\n",
      "  Batch 24,440  of  41,827.    Elapsed: 2:28:34.\n",
      "  Batch 24,480  of  41,827.    Elapsed: 2:28:48.\n",
      "  Batch 24,520  of  41,827.    Elapsed: 2:29:03.\n",
      "  Batch 24,560  of  41,827.    Elapsed: 2:29:18.\n",
      "  Batch 24,600  of  41,827.    Elapsed: 2:29:32.\n",
      "  Batch 24,640  of  41,827.    Elapsed: 2:29:47.\n",
      "  Batch 24,680  of  41,827.    Elapsed: 2:30:01.\n",
      "  Batch 24,720  of  41,827.    Elapsed: 2:30:16.\n",
      "  Batch 24,760  of  41,827.    Elapsed: 2:30:31.\n",
      "  Batch 24,800  of  41,827.    Elapsed: 2:30:45.\n",
      "  Batch 24,840  of  41,827.    Elapsed: 2:31:00.\n",
      "  Batch 24,880  of  41,827.    Elapsed: 2:31:14.\n",
      "  Batch 24,920  of  41,827.    Elapsed: 2:31:29.\n",
      "  Batch 24,960  of  41,827.    Elapsed: 2:31:44.\n",
      "  Batch 25,000  of  41,827.    Elapsed: 2:31:58.\n",
      "  Batch 25,040  of  41,827.    Elapsed: 2:32:13.\n",
      "  Batch 25,080  of  41,827.    Elapsed: 2:32:28.\n",
      "  Batch 25,120  of  41,827.    Elapsed: 2:32:42.\n",
      "  Batch 25,160  of  41,827.    Elapsed: 2:32:57.\n",
      "  Batch 25,200  of  41,827.    Elapsed: 2:33:11.\n",
      "  Batch 25,240  of  41,827.    Elapsed: 2:33:26.\n",
      "  Batch 25,280  of  41,827.    Elapsed: 2:33:41.\n",
      "  Batch 25,320  of  41,827.    Elapsed: 2:33:55.\n",
      "  Batch 25,360  of  41,827.    Elapsed: 2:34:10.\n",
      "  Batch 25,400  of  41,827.    Elapsed: 2:34:24.\n",
      "  Batch 25,440  of  41,827.    Elapsed: 2:34:39.\n",
      "  Batch 25,480  of  41,827.    Elapsed: 2:34:54.\n",
      "  Batch 25,520  of  41,827.    Elapsed: 2:35:08.\n",
      "  Batch 25,560  of  41,827.    Elapsed: 2:35:23.\n",
      "  Batch 25,600  of  41,827.    Elapsed: 2:35:38.\n",
      "  Batch 25,640  of  41,827.    Elapsed: 2:35:52.\n",
      "  Batch 25,680  of  41,827.    Elapsed: 2:36:07.\n",
      "  Batch 25,720  of  41,827.    Elapsed: 2:36:21.\n",
      "  Batch 25,760  of  41,827.    Elapsed: 2:36:36.\n",
      "  Batch 25,800  of  41,827.    Elapsed: 2:36:51.\n",
      "  Batch 25,840  of  41,827.    Elapsed: 2:37:05.\n",
      "  Batch 25,880  of  41,827.    Elapsed: 2:37:20.\n",
      "  Batch 25,920  of  41,827.    Elapsed: 2:37:35.\n",
      "  Batch 25,960  of  41,827.    Elapsed: 2:37:49.\n",
      "  Batch 26,000  of  41,827.    Elapsed: 2:38:04.\n",
      "  Batch 26,040  of  41,827.    Elapsed: 2:38:18.\n",
      "  Batch 26,080  of  41,827.    Elapsed: 2:38:33.\n",
      "  Batch 26,120  of  41,827.    Elapsed: 2:38:48.\n",
      "  Batch 26,160  of  41,827.    Elapsed: 2:39:02.\n",
      "  Batch 26,200  of  41,827.    Elapsed: 2:39:17.\n",
      "  Batch 26,240  of  41,827.    Elapsed: 2:39:32.\n",
      "  Batch 26,280  of  41,827.    Elapsed: 2:39:46.\n",
      "  Batch 26,320  of  41,827.    Elapsed: 2:40:01.\n",
      "  Batch 26,360  of  41,827.    Elapsed: 2:40:15.\n",
      "  Batch 26,400  of  41,827.    Elapsed: 2:40:30.\n",
      "  Batch 26,440  of  41,827.    Elapsed: 2:40:45.\n",
      "  Batch 26,480  of  41,827.    Elapsed: 2:40:59.\n",
      "  Batch 26,520  of  41,827.    Elapsed: 2:41:14.\n",
      "  Batch 26,560  of  41,827.    Elapsed: 2:41:29.\n",
      "  Batch 26,600  of  41,827.    Elapsed: 2:41:43.\n",
      "  Batch 26,640  of  41,827.    Elapsed: 2:41:58.\n",
      "  Batch 26,680  of  41,827.    Elapsed: 2:42:12.\n",
      "  Batch 26,720  of  41,827.    Elapsed: 2:42:27.\n",
      "  Batch 26,760  of  41,827.    Elapsed: 2:42:42.\n",
      "  Batch 26,800  of  41,827.    Elapsed: 2:42:56.\n",
      "  Batch 26,840  of  41,827.    Elapsed: 2:43:11.\n",
      "  Batch 26,880  of  41,827.    Elapsed: 2:43:26.\n",
      "  Batch 26,920  of  41,827.    Elapsed: 2:43:40.\n",
      "  Batch 26,960  of  41,827.    Elapsed: 2:43:55.\n",
      "  Batch 27,000  of  41,827.    Elapsed: 2:44:10.\n",
      "  Batch 27,040  of  41,827.    Elapsed: 2:44:24.\n",
      "  Batch 27,080  of  41,827.    Elapsed: 2:44:39.\n",
      "  Batch 27,120  of  41,827.    Elapsed: 2:44:53.\n",
      "  Batch 27,160  of  41,827.    Elapsed: 2:45:08.\n",
      "  Batch 27,200  of  41,827.    Elapsed: 2:45:23.\n",
      "  Batch 27,240  of  41,827.    Elapsed: 2:45:37.\n",
      "  Batch 27,280  of  41,827.    Elapsed: 2:45:52.\n",
      "  Batch 27,320  of  41,827.    Elapsed: 2:46:07.\n",
      "  Batch 27,360  of  41,827.    Elapsed: 2:46:21.\n",
      "  Batch 27,400  of  41,827.    Elapsed: 2:46:36.\n",
      "  Batch 27,440  of  41,827.    Elapsed: 2:46:51.\n",
      "  Batch 27,480  of  41,827.    Elapsed: 2:47:05.\n",
      "  Batch 27,520  of  41,827.    Elapsed: 2:47:20.\n",
      "  Batch 27,560  of  41,827.    Elapsed: 2:47:35.\n",
      "  Batch 27,600  of  41,827.    Elapsed: 2:47:49.\n",
      "  Batch 27,640  of  41,827.    Elapsed: 2:48:04.\n",
      "  Batch 27,680  of  41,827.    Elapsed: 2:48:19.\n",
      "  Batch 27,720  of  41,827.    Elapsed: 2:48:33.\n",
      "  Batch 27,760  of  41,827.    Elapsed: 2:48:48.\n",
      "  Batch 27,800  of  41,827.    Elapsed: 2:49:02.\n",
      "  Batch 27,840  of  41,827.    Elapsed: 2:49:17.\n",
      "  Batch 27,880  of  41,827.    Elapsed: 2:49:32.\n",
      "  Batch 27,920  of  41,827.    Elapsed: 2:49:46.\n",
      "  Batch 27,960  of  41,827.    Elapsed: 2:50:01.\n",
      "  Batch 28,000  of  41,827.    Elapsed: 2:50:16.\n",
      "  Batch 28,040  of  41,827.    Elapsed: 2:50:30.\n",
      "  Batch 28,080  of  41,827.    Elapsed: 2:50:45.\n",
      "  Batch 28,120  of  41,827.    Elapsed: 2:51:00.\n",
      "  Batch 28,160  of  41,827.    Elapsed: 2:51:14.\n",
      "  Batch 28,200  of  41,827.    Elapsed: 2:51:29.\n",
      "  Batch 28,240  of  41,827.    Elapsed: 2:51:43.\n",
      "  Batch 28,280  of  41,827.    Elapsed: 2:51:58.\n",
      "  Batch 28,320  of  41,827.    Elapsed: 2:52:13.\n",
      "  Batch 28,360  of  41,827.    Elapsed: 2:52:27.\n",
      "  Batch 28,400  of  41,827.    Elapsed: 2:52:42.\n",
      "  Batch 28,440  of  41,827.    Elapsed: 2:52:57.\n",
      "  Batch 28,480  of  41,827.    Elapsed: 2:53:11.\n",
      "  Batch 28,520  of  41,827.    Elapsed: 2:53:26.\n",
      "  Batch 28,560  of  41,827.    Elapsed: 2:53:40.\n",
      "  Batch 28,600  of  41,827.    Elapsed: 2:53:55.\n",
      "  Batch 28,640  of  41,827.    Elapsed: 2:54:10.\n",
      "  Batch 28,680  of  41,827.    Elapsed: 2:54:24.\n",
      "  Batch 28,720  of  41,827.    Elapsed: 2:54:39.\n",
      "  Batch 28,760  of  41,827.    Elapsed: 2:54:53.\n",
      "  Batch 28,800  of  41,827.    Elapsed: 2:55:08.\n",
      "  Batch 28,840  of  41,827.    Elapsed: 2:55:23.\n",
      "  Batch 28,880  of  41,827.    Elapsed: 2:55:37.\n",
      "  Batch 28,920  of  41,827.    Elapsed: 2:55:52.\n",
      "  Batch 28,960  of  41,827.    Elapsed: 2:56:07.\n",
      "  Batch 29,000  of  41,827.    Elapsed: 2:56:21.\n",
      "  Batch 29,040  of  41,827.    Elapsed: 2:56:36.\n",
      "  Batch 29,080  of  41,827.    Elapsed: 2:56:50.\n",
      "  Batch 29,120  of  41,827.    Elapsed: 2:57:05.\n",
      "  Batch 29,160  of  41,827.    Elapsed: 2:57:20.\n",
      "  Batch 29,200  of  41,827.    Elapsed: 2:57:34.\n",
      "  Batch 29,240  of  41,827.    Elapsed: 2:57:49.\n",
      "  Batch 29,280  of  41,827.    Elapsed: 2:58:03.\n",
      "  Batch 29,320  of  41,827.    Elapsed: 2:58:18.\n",
      "  Batch 29,360  of  41,827.    Elapsed: 2:58:33.\n",
      "  Batch 29,400  of  41,827.    Elapsed: 2:58:47.\n",
      "  Batch 29,440  of  41,827.    Elapsed: 2:59:02.\n",
      "  Batch 29,480  of  41,827.    Elapsed: 2:59:17.\n",
      "  Batch 29,520  of  41,827.    Elapsed: 2:59:31.\n",
      "  Batch 29,560  of  41,827.    Elapsed: 2:59:46.\n",
      "  Batch 29,600  of  41,827.    Elapsed: 3:00:00.\n",
      "  Batch 29,640  of  41,827.    Elapsed: 3:00:15.\n",
      "  Batch 29,680  of  41,827.    Elapsed: 3:00:30.\n",
      "  Batch 29,720  of  41,827.    Elapsed: 3:00:44.\n",
      "  Batch 29,760  of  41,827.    Elapsed: 3:00:59.\n",
      "  Batch 29,800  of  41,827.    Elapsed: 3:01:13.\n",
      "  Batch 29,840  of  41,827.    Elapsed: 3:01:28.\n",
      "  Batch 29,880  of  41,827.    Elapsed: 3:01:43.\n",
      "  Batch 29,920  of  41,827.    Elapsed: 3:01:57.\n",
      "  Batch 29,960  of  41,827.    Elapsed: 3:02:12.\n",
      "  Batch 30,000  of  41,827.    Elapsed: 3:02:26.\n",
      "  Batch 30,040  of  41,827.    Elapsed: 3:02:41.\n",
      "  Batch 30,080  of  41,827.    Elapsed: 3:02:56.\n",
      "  Batch 30,120  of  41,827.    Elapsed: 3:03:10.\n",
      "  Batch 30,160  of  41,827.    Elapsed: 3:03:25.\n",
      "  Batch 30,200  of  41,827.    Elapsed: 3:03:39.\n",
      "  Batch 30,240  of  41,827.    Elapsed: 3:03:54.\n",
      "  Batch 30,280  of  41,827.    Elapsed: 3:04:09.\n",
      "  Batch 30,320  of  41,827.    Elapsed: 3:04:23.\n",
      "  Batch 30,360  of  41,827.    Elapsed: 3:04:38.\n",
      "  Batch 30,400  of  41,827.    Elapsed: 3:04:52.\n",
      "  Batch 30,440  of  41,827.    Elapsed: 3:05:07.\n",
      "  Batch 30,480  of  41,827.    Elapsed: 3:05:22.\n",
      "  Batch 30,520  of  41,827.    Elapsed: 3:05:36.\n",
      "  Batch 30,560  of  41,827.    Elapsed: 3:05:51.\n",
      "  Batch 30,600  of  41,827.    Elapsed: 3:06:05.\n",
      "  Batch 30,640  of  41,827.    Elapsed: 3:06:20.\n",
      "  Batch 30,680  of  41,827.    Elapsed: 3:06:35.\n",
      "  Batch 30,720  of  41,827.    Elapsed: 3:06:49.\n",
      "  Batch 30,760  of  41,827.    Elapsed: 3:07:04.\n",
      "  Batch 30,800  of  41,827.    Elapsed: 3:07:18.\n",
      "  Batch 30,840  of  41,827.    Elapsed: 3:07:33.\n",
      "  Batch 30,880  of  41,827.    Elapsed: 3:07:48.\n",
      "  Batch 30,920  of  41,827.    Elapsed: 3:08:02.\n",
      "  Batch 30,960  of  41,827.    Elapsed: 3:08:17.\n",
      "  Batch 31,000  of  41,827.    Elapsed: 3:08:32.\n",
      "  Batch 31,040  of  41,827.    Elapsed: 3:08:46.\n",
      "  Batch 31,080  of  41,827.    Elapsed: 3:09:01.\n",
      "  Batch 31,120  of  41,827.    Elapsed: 3:09:15.\n",
      "  Batch 31,160  of  41,827.    Elapsed: 3:09:30.\n",
      "  Batch 31,200  of  41,827.    Elapsed: 3:09:45.\n",
      "  Batch 31,240  of  41,827.    Elapsed: 3:09:59.\n",
      "  Batch 31,280  of  41,827.    Elapsed: 3:10:14.\n",
      "  Batch 31,320  of  41,827.    Elapsed: 3:10:28.\n",
      "  Batch 31,360  of  41,827.    Elapsed: 3:10:43.\n",
      "  Batch 31,400  of  41,827.    Elapsed: 3:10:57.\n",
      "  Batch 31,440  of  41,827.    Elapsed: 3:11:12.\n",
      "  Batch 31,480  of  41,827.    Elapsed: 3:11:27.\n",
      "  Batch 31,520  of  41,827.    Elapsed: 3:11:41.\n",
      "  Batch 31,560  of  41,827.    Elapsed: 3:11:56.\n",
      "  Batch 31,600  of  41,827.    Elapsed: 3:12:10.\n",
      "  Batch 31,640  of  41,827.    Elapsed: 3:12:25.\n",
      "  Batch 31,680  of  41,827.    Elapsed: 3:12:40.\n",
      "  Batch 31,720  of  41,827.    Elapsed: 3:12:54.\n",
      "  Batch 31,760  of  41,827.    Elapsed: 3:13:09.\n",
      "  Batch 31,800  of  41,827.    Elapsed: 3:13:23.\n",
      "  Batch 31,840  of  41,827.    Elapsed: 3:13:38.\n",
      "  Batch 31,880  of  41,827.    Elapsed: 3:13:52.\n",
      "  Batch 31,920  of  41,827.    Elapsed: 3:14:07.\n",
      "  Batch 31,960  of  41,827.    Elapsed: 3:14:22.\n",
      "  Batch 32,000  of  41,827.    Elapsed: 3:14:36.\n",
      "  Batch 32,040  of  41,827.    Elapsed: 3:14:51.\n",
      "  Batch 32,080  of  41,827.    Elapsed: 3:15:05.\n",
      "  Batch 32,120  of  41,827.    Elapsed: 3:15:20.\n",
      "  Batch 32,160  of  41,827.    Elapsed: 3:15:35.\n",
      "  Batch 32,200  of  41,827.    Elapsed: 3:15:49.\n",
      "  Batch 32,240  of  41,827.    Elapsed: 3:16:04.\n",
      "  Batch 32,280  of  41,827.    Elapsed: 3:16:18.\n",
      "  Batch 32,320  of  41,827.    Elapsed: 3:16:33.\n",
      "  Batch 32,360  of  41,827.    Elapsed: 3:16:47.\n",
      "  Batch 32,400  of  41,827.    Elapsed: 3:17:02.\n",
      "  Batch 32,440  of  41,827.    Elapsed: 3:17:17.\n",
      "  Batch 32,480  of  41,827.    Elapsed: 3:17:31.\n",
      "  Batch 32,520  of  41,827.    Elapsed: 3:17:46.\n",
      "  Batch 32,560  of  41,827.    Elapsed: 3:18:00.\n",
      "  Batch 32,600  of  41,827.    Elapsed: 3:18:15.\n",
      "  Batch 32,640  of  41,827.    Elapsed: 3:18:29.\n",
      "  Batch 32,680  of  41,827.    Elapsed: 3:18:44.\n",
      "  Batch 32,720  of  41,827.    Elapsed: 3:18:59.\n",
      "  Batch 32,760  of  41,827.    Elapsed: 3:19:13.\n",
      "  Batch 32,800  of  41,827.    Elapsed: 3:19:28.\n",
      "  Batch 32,840  of  41,827.    Elapsed: 3:19:42.\n",
      "  Batch 32,880  of  41,827.    Elapsed: 3:19:57.\n",
      "  Batch 32,920  of  41,827.    Elapsed: 3:20:12.\n",
      "  Batch 32,960  of  41,827.    Elapsed: 3:20:26.\n",
      "  Batch 33,000  of  41,827.    Elapsed: 3:20:41.\n",
      "  Batch 33,040  of  41,827.    Elapsed: 3:20:55.\n",
      "  Batch 33,080  of  41,827.    Elapsed: 3:21:10.\n",
      "  Batch 33,120  of  41,827.    Elapsed: 3:21:25.\n",
      "  Batch 33,160  of  41,827.    Elapsed: 3:21:39.\n",
      "  Batch 33,200  of  41,827.    Elapsed: 3:21:54.\n",
      "  Batch 33,240  of  41,827.    Elapsed: 3:22:08.\n",
      "  Batch 33,280  of  41,827.    Elapsed: 3:22:23.\n",
      "  Batch 33,320  of  41,827.    Elapsed: 3:22:38.\n",
      "  Batch 33,360  of  41,827.    Elapsed: 3:22:52.\n",
      "  Batch 33,400  of  41,827.    Elapsed: 3:23:07.\n",
      "  Batch 33,440  of  41,827.    Elapsed: 3:23:21.\n",
      "  Batch 33,480  of  41,827.    Elapsed: 3:23:36.\n",
      "  Batch 33,520  of  41,827.    Elapsed: 3:23:50.\n",
      "  Batch 33,560  of  41,827.    Elapsed: 3:24:05.\n",
      "  Batch 33,600  of  41,827.    Elapsed: 3:24:20.\n",
      "  Batch 33,640  of  41,827.    Elapsed: 3:24:34.\n",
      "  Batch 33,680  of  41,827.    Elapsed: 3:24:49.\n",
      "  Batch 33,720  of  41,827.    Elapsed: 3:25:03.\n",
      "  Batch 33,760  of  41,827.    Elapsed: 3:25:18.\n",
      "  Batch 33,800  of  41,827.    Elapsed: 3:25:33.\n",
      "  Batch 33,840  of  41,827.    Elapsed: 3:25:47.\n",
      "  Batch 33,880  of  41,827.    Elapsed: 3:26:02.\n",
      "  Batch 33,920  of  41,827.    Elapsed: 3:26:16.\n",
      "  Batch 33,960  of  41,827.    Elapsed: 3:26:31.\n",
      "  Batch 34,000  of  41,827.    Elapsed: 3:26:46.\n",
      "  Batch 34,040  of  41,827.    Elapsed: 3:27:00.\n",
      "  Batch 34,080  of  41,827.    Elapsed: 3:27:15.\n",
      "  Batch 34,120  of  41,827.    Elapsed: 3:27:29.\n",
      "  Batch 34,160  of  41,827.    Elapsed: 3:27:44.\n",
      "  Batch 34,200  of  41,827.    Elapsed: 3:27:59.\n",
      "  Batch 34,240  of  41,827.    Elapsed: 3:28:13.\n",
      "  Batch 34,280  of  41,827.    Elapsed: 3:28:28.\n",
      "  Batch 34,320  of  41,827.    Elapsed: 3:28:42.\n",
      "  Batch 34,360  of  41,827.    Elapsed: 3:28:57.\n",
      "  Batch 34,400  of  41,827.    Elapsed: 3:29:12.\n",
      "  Batch 34,440  of  41,827.    Elapsed: 3:29:26.\n",
      "  Batch 34,480  of  41,827.    Elapsed: 3:29:41.\n",
      "  Batch 34,520  of  41,827.    Elapsed: 3:29:55.\n",
      "  Batch 34,560  of  41,827.    Elapsed: 3:30:10.\n",
      "  Batch 34,600  of  41,827.    Elapsed: 3:30:25.\n",
      "  Batch 34,640  of  41,827.    Elapsed: 3:30:39.\n",
      "  Batch 34,680  of  41,827.    Elapsed: 3:30:54.\n",
      "  Batch 34,720  of  41,827.    Elapsed: 3:31:08.\n",
      "  Batch 34,760  of  41,827.    Elapsed: 3:31:23.\n",
      "  Batch 34,800  of  41,827.    Elapsed: 3:31:37.\n",
      "  Batch 34,840  of  41,827.    Elapsed: 3:31:52.\n",
      "  Batch 34,880  of  41,827.    Elapsed: 3:32:07.\n",
      "  Batch 34,920  of  41,827.    Elapsed: 3:32:21.\n",
      "  Batch 34,960  of  41,827.    Elapsed: 3:32:36.\n",
      "  Batch 35,000  of  41,827.    Elapsed: 3:32:50.\n",
      "  Batch 35,040  of  41,827.    Elapsed: 3:33:05.\n",
      "  Batch 35,080  of  41,827.    Elapsed: 3:33:20.\n",
      "  Batch 35,120  of  41,827.    Elapsed: 3:33:34.\n",
      "  Batch 35,160  of  41,827.    Elapsed: 3:33:49.\n",
      "  Batch 35,200  of  41,827.    Elapsed: 3:34:03.\n",
      "  Batch 35,240  of  41,827.    Elapsed: 3:34:18.\n",
      "  Batch 35,280  of  41,827.    Elapsed: 3:34:33.\n",
      "  Batch 35,320  of  41,827.    Elapsed: 3:34:47.\n",
      "  Batch 35,360  of  41,827.    Elapsed: 3:35:02.\n",
      "  Batch 35,400  of  41,827.    Elapsed: 3:35:16.\n",
      "  Batch 35,440  of  41,827.    Elapsed: 3:35:31.\n",
      "  Batch 35,480  of  41,827.    Elapsed: 3:35:46.\n",
      "  Batch 35,520  of  41,827.    Elapsed: 3:36:00.\n",
      "  Batch 35,560  of  41,827.    Elapsed: 3:36:15.\n",
      "  Batch 35,600  of  41,827.    Elapsed: 3:36:29.\n",
      "  Batch 35,640  of  41,827.    Elapsed: 3:36:44.\n",
      "  Batch 35,680  of  41,827.    Elapsed: 3:36:59.\n",
      "  Batch 35,720  of  41,827.    Elapsed: 3:37:13.\n",
      "  Batch 35,760  of  41,827.    Elapsed: 3:37:28.\n",
      "  Batch 35,800  of  41,827.    Elapsed: 3:37:42.\n",
      "  Batch 35,840  of  41,827.    Elapsed: 3:37:57.\n",
      "  Batch 35,880  of  41,827.    Elapsed: 3:38:12.\n",
      "  Batch 35,920  of  41,827.    Elapsed: 3:38:26.\n",
      "  Batch 35,960  of  41,827.    Elapsed: 3:38:41.\n",
      "  Batch 36,000  of  41,827.    Elapsed: 3:38:55.\n",
      "  Batch 36,040  of  41,827.    Elapsed: 3:39:10.\n",
      "  Batch 36,080  of  41,827.    Elapsed: 3:39:25.\n",
      "  Batch 36,120  of  41,827.    Elapsed: 3:39:39.\n",
      "  Batch 36,160  of  41,827.    Elapsed: 3:39:54.\n",
      "  Batch 36,200  of  41,827.    Elapsed: 3:40:08.\n",
      "  Batch 36,240  of  41,827.    Elapsed: 3:40:23.\n",
      "  Batch 36,280  of  41,827.    Elapsed: 3:40:38.\n",
      "  Batch 36,320  of  41,827.    Elapsed: 3:40:52.\n",
      "  Batch 36,360  of  41,827.    Elapsed: 3:41:07.\n",
      "  Batch 36,400  of  41,827.    Elapsed: 3:41:21.\n",
      "  Batch 36,440  of  41,827.    Elapsed: 3:41:36.\n",
      "  Batch 36,480  of  41,827.    Elapsed: 3:41:51.\n",
      "  Batch 36,520  of  41,827.    Elapsed: 3:42:05.\n",
      "  Batch 36,560  of  41,827.    Elapsed: 3:42:20.\n",
      "  Batch 36,600  of  41,827.    Elapsed: 3:42:35.\n",
      "  Batch 36,640  of  41,827.    Elapsed: 3:42:49.\n",
      "  Batch 36,680  of  41,827.    Elapsed: 3:43:04.\n",
      "  Batch 36,720  of  41,827.    Elapsed: 3:43:18.\n",
      "  Batch 36,760  of  41,827.    Elapsed: 3:43:33.\n",
      "  Batch 36,800  of  41,827.    Elapsed: 3:43:48.\n",
      "  Batch 36,840  of  41,827.    Elapsed: 3:44:02.\n",
      "  Batch 36,880  of  41,827.    Elapsed: 3:44:17.\n",
      "  Batch 36,920  of  41,827.    Elapsed: 3:44:31.\n",
      "  Batch 36,960  of  41,827.    Elapsed: 3:44:46.\n",
      "  Batch 37,000  of  41,827.    Elapsed: 3:45:01.\n",
      "  Batch 37,040  of  41,827.    Elapsed: 3:45:15.\n",
      "  Batch 37,080  of  41,827.    Elapsed: 3:45:30.\n",
      "  Batch 37,120  of  41,827.    Elapsed: 3:45:45.\n",
      "  Batch 37,160  of  41,827.    Elapsed: 3:45:59.\n",
      "  Batch 37,200  of  41,827.    Elapsed: 3:46:14.\n",
      "  Batch 37,240  of  41,827.    Elapsed: 3:46:29.\n",
      "  Batch 37,280  of  41,827.    Elapsed: 3:46:43.\n",
      "  Batch 37,320  of  41,827.    Elapsed: 3:46:58.\n",
      "  Batch 37,360  of  41,827.    Elapsed: 3:47:12.\n",
      "  Batch 37,400  of  41,827.    Elapsed: 3:47:27.\n",
      "  Batch 37,440  of  41,827.    Elapsed: 3:47:42.\n",
      "  Batch 37,480  of  41,827.    Elapsed: 3:47:56.\n",
      "  Batch 37,520  of  41,827.    Elapsed: 3:48:11.\n",
      "  Batch 37,560  of  41,827.    Elapsed: 3:48:26.\n",
      "  Batch 37,600  of  41,827.    Elapsed: 3:48:40.\n",
      "  Batch 37,640  of  41,827.    Elapsed: 3:48:55.\n",
      "  Batch 37,680  of  41,827.    Elapsed: 3:49:09.\n",
      "  Batch 37,720  of  41,827.    Elapsed: 3:49:24.\n",
      "  Batch 37,760  of  41,827.    Elapsed: 3:49:39.\n",
      "  Batch 37,800  of  41,827.    Elapsed: 3:49:53.\n",
      "  Batch 37,840  of  41,827.    Elapsed: 3:50:08.\n",
      "  Batch 37,880  of  41,827.    Elapsed: 3:50:22.\n",
      "  Batch 37,920  of  41,827.    Elapsed: 3:50:37.\n",
      "  Batch 37,960  of  41,827.    Elapsed: 3:50:52.\n",
      "  Batch 38,000  of  41,827.    Elapsed: 3:51:06.\n",
      "  Batch 38,040  of  41,827.    Elapsed: 3:51:21.\n",
      "  Batch 38,080  of  41,827.    Elapsed: 3:51:36.\n",
      "  Batch 38,120  of  41,827.    Elapsed: 3:51:50.\n",
      "  Batch 38,160  of  41,827.    Elapsed: 3:52:05.\n",
      "  Batch 38,200  of  41,827.    Elapsed: 3:52:19.\n",
      "  Batch 38,240  of  41,827.    Elapsed: 3:52:34.\n",
      "  Batch 38,280  of  41,827.    Elapsed: 3:52:49.\n",
      "  Batch 38,320  of  41,827.    Elapsed: 3:53:03.\n",
      "  Batch 38,360  of  41,827.    Elapsed: 3:53:18.\n",
      "  Batch 38,400  of  41,827.    Elapsed: 3:53:33.\n",
      "  Batch 38,440  of  41,827.    Elapsed: 3:53:47.\n",
      "  Batch 38,480  of  41,827.    Elapsed: 3:54:02.\n",
      "  Batch 38,520  of  41,827.    Elapsed: 3:54:16.\n",
      "  Batch 38,560  of  41,827.    Elapsed: 3:54:31.\n",
      "  Batch 38,600  of  41,827.    Elapsed: 3:54:45.\n",
      "  Batch 38,640  of  41,827.    Elapsed: 3:55:00.\n",
      "  Batch 38,680  of  41,827.    Elapsed: 3:55:15.\n",
      "  Batch 38,720  of  41,827.    Elapsed: 3:55:29.\n",
      "  Batch 38,760  of  41,827.    Elapsed: 3:55:44.\n",
      "  Batch 38,800  of  41,827.    Elapsed: 3:55:58.\n",
      "  Batch 38,840  of  41,827.    Elapsed: 3:56:13.\n",
      "  Batch 38,880  of  41,827.    Elapsed: 3:56:28.\n",
      "  Batch 38,920  of  41,827.    Elapsed: 3:56:42.\n",
      "  Batch 38,960  of  41,827.    Elapsed: 3:56:57.\n",
      "  Batch 39,000  of  41,827.    Elapsed: 3:57:11.\n",
      "  Batch 39,040  of  41,827.    Elapsed: 3:57:26.\n",
      "  Batch 39,080  of  41,827.    Elapsed: 3:57:41.\n",
      "  Batch 39,120  of  41,827.    Elapsed: 3:57:55.\n",
      "  Batch 39,160  of  41,827.    Elapsed: 3:58:10.\n",
      "  Batch 39,200  of  41,827.    Elapsed: 3:58:24.\n",
      "  Batch 39,240  of  41,827.    Elapsed: 3:58:39.\n",
      "  Batch 39,280  of  41,827.    Elapsed: 3:58:54.\n",
      "  Batch 39,320  of  41,827.    Elapsed: 3:59:08.\n",
      "  Batch 39,360  of  41,827.    Elapsed: 3:59:23.\n",
      "  Batch 39,400  of  41,827.    Elapsed: 3:59:37.\n",
      "  Batch 39,440  of  41,827.    Elapsed: 3:59:52.\n",
      "  Batch 39,480  of  41,827.    Elapsed: 4:00:07.\n",
      "  Batch 39,520  of  41,827.    Elapsed: 4:00:21.\n",
      "  Batch 39,560  of  41,827.    Elapsed: 4:00:36.\n",
      "  Batch 39,600  of  41,827.    Elapsed: 4:00:50.\n",
      "  Batch 39,640  of  41,827.    Elapsed: 4:01:05.\n",
      "  Batch 39,680  of  41,827.    Elapsed: 4:01:20.\n",
      "  Batch 39,720  of  41,827.    Elapsed: 4:01:34.\n",
      "  Batch 39,760  of  41,827.    Elapsed: 4:01:49.\n",
      "  Batch 39,800  of  41,827.    Elapsed: 4:02:03.\n",
      "  Batch 39,840  of  41,827.    Elapsed: 4:02:18.\n",
      "  Batch 39,880  of  41,827.    Elapsed: 4:02:33.\n",
      "  Batch 39,920  of  41,827.    Elapsed: 4:02:47.\n",
      "  Batch 39,960  of  41,827.    Elapsed: 4:03:02.\n",
      "  Batch 40,000  of  41,827.    Elapsed: 4:03:16.\n",
      "  Batch 40,040  of  41,827.    Elapsed: 4:03:31.\n",
      "  Batch 40,080  of  41,827.    Elapsed: 4:03:46.\n",
      "  Batch 40,120  of  41,827.    Elapsed: 4:04:00.\n",
      "  Batch 40,160  of  41,827.    Elapsed: 4:04:15.\n",
      "  Batch 40,200  of  41,827.    Elapsed: 4:04:29.\n",
      "  Batch 40,240  of  41,827.    Elapsed: 4:04:44.\n",
      "  Batch 40,280  of  41,827.    Elapsed: 4:04:59.\n",
      "  Batch 40,320  of  41,827.    Elapsed: 4:05:13.\n",
      "  Batch 40,360  of  41,827.    Elapsed: 4:05:28.\n",
      "  Batch 40,400  of  41,827.    Elapsed: 4:05:42.\n",
      "  Batch 40,440  of  41,827.    Elapsed: 4:05:57.\n",
      "  Batch 40,480  of  41,827.    Elapsed: 4:06:11.\n",
      "  Batch 40,520  of  41,827.    Elapsed: 4:06:26.\n",
      "  Batch 40,560  of  41,827.    Elapsed: 4:06:41.\n",
      "  Batch 40,600  of  41,827.    Elapsed: 4:06:55.\n",
      "  Batch 40,640  of  41,827.    Elapsed: 4:07:10.\n",
      "  Batch 40,680  of  41,827.    Elapsed: 4:07:24.\n",
      "  Batch 40,720  of  41,827.    Elapsed: 4:07:39.\n",
      "  Batch 40,760  of  41,827.    Elapsed: 4:07:54.\n",
      "  Batch 40,800  of  41,827.    Elapsed: 4:08:08.\n",
      "  Batch 40,840  of  41,827.    Elapsed: 4:08:23.\n",
      "  Batch 40,880  of  41,827.    Elapsed: 4:08:37.\n",
      "  Batch 40,920  of  41,827.    Elapsed: 4:08:52.\n",
      "  Batch 40,960  of  41,827.    Elapsed: 4:09:07.\n",
      "  Batch 41,000  of  41,827.    Elapsed: 4:09:21.\n",
      "  Batch 41,040  of  41,827.    Elapsed: 4:09:36.\n",
      "  Batch 41,080  of  41,827.    Elapsed: 4:09:50.\n",
      "  Batch 41,120  of  41,827.    Elapsed: 4:10:05.\n",
      "  Batch 41,160  of  41,827.    Elapsed: 4:10:20.\n",
      "  Batch 41,200  of  41,827.    Elapsed: 4:10:34.\n",
      "  Batch 41,240  of  41,827.    Elapsed: 4:10:49.\n",
      "  Batch 41,280  of  41,827.    Elapsed: 4:11:03.\n",
      "  Batch 41,320  of  41,827.    Elapsed: 4:11:18.\n",
      "  Batch 41,360  of  41,827.    Elapsed: 4:11:33.\n",
      "  Batch 41,400  of  41,827.    Elapsed: 4:11:47.\n",
      "  Batch 41,440  of  41,827.    Elapsed: 4:12:02.\n",
      "  Batch 41,480  of  41,827.    Elapsed: 4:12:17.\n",
      "  Batch 41,520  of  41,827.    Elapsed: 4:12:31.\n",
      "  Batch 41,560  of  41,827.    Elapsed: 4:12:46.\n",
      "  Batch 41,600  of  41,827.    Elapsed: 4:13:00.\n",
      "  Batch 41,640  of  41,827.    Elapsed: 4:13:15.\n",
      "  Batch 41,680  of  41,827.    Elapsed: 4:13:30.\n",
      "  Batch 41,720  of  41,827.    Elapsed: 4:13:44.\n",
      "  Batch 41,760  of  41,827.    Elapsed: 4:13:59.\n",
      "  Batch 41,800  of  41,827.    Elapsed: 4:14:14.\n",
      "\n",
      "  Average training loss: 0.32\n",
      "  Training epcoh took: 4:14:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:08:50\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  41,827.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  41,827.    Elapsed: 0:00:29.\n",
      "  Batch   120  of  41,827.    Elapsed: 0:00:44.\n",
      "  Batch   160  of  41,827.    Elapsed: 0:00:59.\n",
      "  Batch   200  of  41,827.    Elapsed: 0:01:13.\n",
      "  Batch   240  of  41,827.    Elapsed: 0:01:28.\n",
      "  Batch   280  of  41,827.    Elapsed: 0:01:43.\n",
      "  Batch   320  of  41,827.    Elapsed: 0:01:57.\n",
      "  Batch   360  of  41,827.    Elapsed: 0:02:12.\n",
      "  Batch   400  of  41,827.    Elapsed: 0:02:26.\n",
      "  Batch   440  of  41,827.    Elapsed: 0:02:41.\n",
      "  Batch   480  of  41,827.    Elapsed: 0:02:56.\n",
      "  Batch   520  of  41,827.    Elapsed: 0:03:10.\n",
      "  Batch   560  of  41,827.    Elapsed: 0:03:25.\n",
      "  Batch   600  of  41,827.    Elapsed: 0:03:39.\n",
      "  Batch   640  of  41,827.    Elapsed: 0:03:54.\n",
      "  Batch   680  of  41,827.    Elapsed: 0:04:09.\n",
      "  Batch   720  of  41,827.    Elapsed: 0:04:23.\n",
      "  Batch   760  of  41,827.    Elapsed: 0:04:38.\n",
      "  Batch   800  of  41,827.    Elapsed: 0:04:52.\n",
      "  Batch   840  of  41,827.    Elapsed: 0:05:07.\n",
      "  Batch   880  of  41,827.    Elapsed: 0:05:22.\n",
      "  Batch   920  of  41,827.    Elapsed: 0:05:36.\n",
      "  Batch   960  of  41,827.    Elapsed: 0:05:51.\n",
      "  Batch 1,000  of  41,827.    Elapsed: 0:06:06.\n",
      "  Batch 1,040  of  41,827.    Elapsed: 0:06:20.\n",
      "  Batch 1,080  of  41,827.    Elapsed: 0:06:35.\n",
      "  Batch 1,120  of  41,827.    Elapsed: 0:06:49.\n",
      "  Batch 1,160  of  41,827.    Elapsed: 0:07:04.\n",
      "  Batch 1,200  of  41,827.    Elapsed: 0:07:19.\n",
      "  Batch 1,240  of  41,827.    Elapsed: 0:07:33.\n",
      "  Batch 1,280  of  41,827.    Elapsed: 0:07:48.\n",
      "  Batch 1,320  of  41,827.    Elapsed: 0:08:03.\n",
      "  Batch 1,360  of  41,827.    Elapsed: 0:08:17.\n",
      "  Batch 1,400  of  41,827.    Elapsed: 0:08:32.\n",
      "  Batch 1,440  of  41,827.    Elapsed: 0:08:46.\n",
      "  Batch 1,480  of  41,827.    Elapsed: 0:09:01.\n",
      "  Batch 1,520  of  41,827.    Elapsed: 0:09:16.\n",
      "  Batch 1,560  of  41,827.    Elapsed: 0:09:30.\n",
      "  Batch 1,600  of  41,827.    Elapsed: 0:09:45.\n",
      "  Batch 1,640  of  41,827.    Elapsed: 0:09:59.\n",
      "  Batch 1,680  of  41,827.    Elapsed: 0:10:14.\n",
      "  Batch 1,720  of  41,827.    Elapsed: 0:10:29.\n",
      "  Batch 1,760  of  41,827.    Elapsed: 0:10:43.\n",
      "  Batch 1,800  of  41,827.    Elapsed: 0:10:58.\n",
      "  Batch 1,840  of  41,827.    Elapsed: 0:11:13.\n",
      "  Batch 1,880  of  41,827.    Elapsed: 0:11:27.\n",
      "  Batch 1,920  of  41,827.    Elapsed: 0:11:42.\n",
      "  Batch 1,960  of  41,827.    Elapsed: 0:11:56.\n",
      "  Batch 2,000  of  41,827.    Elapsed: 0:12:11.\n",
      "  Batch 2,040  of  41,827.    Elapsed: 0:12:26.\n",
      "  Batch 2,080  of  41,827.    Elapsed: 0:12:40.\n",
      "  Batch 2,120  of  41,827.    Elapsed: 0:12:55.\n",
      "  Batch 2,160  of  41,827.    Elapsed: 0:13:09.\n",
      "  Batch 2,200  of  41,827.    Elapsed: 0:13:24.\n",
      "  Batch 2,240  of  41,827.    Elapsed: 0:13:39.\n",
      "  Batch 2,280  of  41,827.    Elapsed: 0:13:53.\n",
      "  Batch 2,320  of  41,827.    Elapsed: 0:14:08.\n",
      "  Batch 2,360  of  41,827.    Elapsed: 0:14:23.\n",
      "  Batch 2,400  of  41,827.    Elapsed: 0:14:37.\n",
      "  Batch 2,440  of  41,827.    Elapsed: 0:14:52.\n",
      "  Batch 2,480  of  41,827.    Elapsed: 0:15:06.\n",
      "  Batch 2,520  of  41,827.    Elapsed: 0:15:21.\n",
      "  Batch 2,560  of  41,827.    Elapsed: 0:15:36.\n",
      "  Batch 2,600  of  41,827.    Elapsed: 0:15:50.\n",
      "  Batch 2,640  of  41,827.    Elapsed: 0:16:05.\n",
      "  Batch 2,680  of  41,827.    Elapsed: 0:16:19.\n",
      "  Batch 2,720  of  41,827.    Elapsed: 0:16:34.\n",
      "  Batch 2,760  of  41,827.    Elapsed: 0:16:49.\n",
      "  Batch 2,800  of  41,827.    Elapsed: 0:17:03.\n",
      "  Batch 2,840  of  41,827.    Elapsed: 0:17:18.\n",
      "  Batch 2,880  of  41,827.    Elapsed: 0:17:32.\n",
      "  Batch 2,920  of  41,827.    Elapsed: 0:17:47.\n",
      "  Batch 2,960  of  41,827.    Elapsed: 0:18:02.\n",
      "  Batch 3,000  of  41,827.    Elapsed: 0:18:16.\n",
      "  Batch 3,040  of  41,827.    Elapsed: 0:18:31.\n",
      "  Batch 3,080  of  41,827.    Elapsed: 0:18:46.\n",
      "  Batch 3,120  of  41,827.    Elapsed: 0:19:00.\n",
      "  Batch 3,160  of  41,827.    Elapsed: 0:19:15.\n",
      "  Batch 3,200  of  41,827.    Elapsed: 0:19:29.\n",
      "  Batch 3,240  of  41,827.    Elapsed: 0:19:44.\n",
      "  Batch 3,280  of  41,827.    Elapsed: 0:19:59.\n",
      "  Batch 3,320  of  41,827.    Elapsed: 0:20:13.\n",
      "  Batch 3,360  of  41,827.    Elapsed: 0:20:28.\n",
      "  Batch 3,400  of  41,827.    Elapsed: 0:20:42.\n",
      "  Batch 3,440  of  41,827.    Elapsed: 0:20:57.\n",
      "  Batch 3,480  of  41,827.    Elapsed: 0:21:12.\n",
      "  Batch 3,520  of  41,827.    Elapsed: 0:21:26.\n",
      "  Batch 3,560  of  41,827.    Elapsed: 0:21:41.\n",
      "  Batch 3,600  of  41,827.    Elapsed: 0:21:55.\n",
      "  Batch 3,640  of  41,827.    Elapsed: 0:22:10.\n",
      "  Batch 3,680  of  41,827.    Elapsed: 0:22:25.\n",
      "  Batch 3,720  of  41,827.    Elapsed: 0:22:39.\n",
      "  Batch 3,760  of  41,827.    Elapsed: 0:22:54.\n",
      "  Batch 3,800  of  41,827.    Elapsed: 0:23:08.\n",
      "  Batch 3,840  of  41,827.    Elapsed: 0:23:23.\n",
      "  Batch 3,880  of  41,827.    Elapsed: 0:23:38.\n",
      "  Batch 3,920  of  41,827.    Elapsed: 0:23:52.\n",
      "  Batch 3,960  of  41,827.    Elapsed: 0:24:07.\n",
      "  Batch 4,000  of  41,827.    Elapsed: 0:24:21.\n",
      "  Batch 4,040  of  41,827.    Elapsed: 0:24:36.\n",
      "  Batch 4,080  of  41,827.    Elapsed: 0:24:51.\n",
      "  Batch 4,120  of  41,827.    Elapsed: 0:25:05.\n",
      "  Batch 4,160  of  41,827.    Elapsed: 0:25:20.\n",
      "  Batch 4,200  of  41,827.    Elapsed: 0:25:35.\n",
      "  Batch 4,240  of  41,827.    Elapsed: 0:25:49.\n",
      "  Batch 4,280  of  41,827.    Elapsed: 0:26:04.\n",
      "  Batch 4,320  of  41,827.    Elapsed: 0:26:18.\n",
      "  Batch 4,360  of  41,827.    Elapsed: 0:26:33.\n",
      "  Batch 4,400  of  41,827.    Elapsed: 0:26:48.\n",
      "  Batch 4,440  of  41,827.    Elapsed: 0:27:02.\n",
      "  Batch 4,480  of  41,827.    Elapsed: 0:27:17.\n",
      "  Batch 4,520  of  41,827.    Elapsed: 0:27:31.\n",
      "  Batch 4,560  of  41,827.    Elapsed: 0:27:46.\n",
      "  Batch 4,600  of  41,827.    Elapsed: 0:28:01.\n",
      "  Batch 4,640  of  41,827.    Elapsed: 0:28:15.\n",
      "  Batch 4,680  of  41,827.    Elapsed: 0:28:30.\n",
      "  Batch 4,720  of  41,827.    Elapsed: 0:28:44.\n",
      "  Batch 4,760  of  41,827.    Elapsed: 0:28:59.\n",
      "  Batch 4,800  of  41,827.    Elapsed: 0:29:14.\n",
      "  Batch 4,840  of  41,827.    Elapsed: 0:29:28.\n",
      "  Batch 4,880  of  41,827.    Elapsed: 0:29:43.\n",
      "  Batch 4,920  of  41,827.    Elapsed: 0:29:58.\n",
      "  Batch 4,960  of  41,827.    Elapsed: 0:30:12.\n",
      "  Batch 5,000  of  41,827.    Elapsed: 0:30:27.\n",
      "  Batch 5,040  of  41,827.    Elapsed: 0:30:42.\n",
      "  Batch 5,080  of  41,827.    Elapsed: 0:30:56.\n",
      "  Batch 5,120  of  41,827.    Elapsed: 0:31:11.\n",
      "  Batch 5,160  of  41,827.    Elapsed: 0:31:25.\n",
      "  Batch 5,200  of  41,827.    Elapsed: 0:31:40.\n",
      "  Batch 5,240  of  41,827.    Elapsed: 0:31:55.\n",
      "  Batch 5,280  of  41,827.    Elapsed: 0:32:09.\n",
      "  Batch 5,320  of  41,827.    Elapsed: 0:32:24.\n",
      "  Batch 5,360  of  41,827.    Elapsed: 0:32:38.\n",
      "  Batch 5,400  of  41,827.    Elapsed: 0:32:53.\n",
      "  Batch 5,440  of  41,827.    Elapsed: 0:33:07.\n",
      "  Batch 5,480  of  41,827.    Elapsed: 0:33:22.\n",
      "  Batch 5,520  of  41,827.    Elapsed: 0:33:37.\n",
      "  Batch 5,560  of  41,827.    Elapsed: 0:33:51.\n",
      "  Batch 5,600  of  41,827.    Elapsed: 0:34:06.\n",
      "  Batch 5,640  of  41,827.    Elapsed: 0:34:20.\n",
      "  Batch 5,680  of  41,827.    Elapsed: 0:34:35.\n",
      "  Batch 5,720  of  41,827.    Elapsed: 0:34:50.\n",
      "  Batch 5,760  of  41,827.    Elapsed: 0:35:04.\n",
      "  Batch 5,800  of  41,827.    Elapsed: 0:35:19.\n",
      "  Batch 5,840  of  41,827.    Elapsed: 0:35:33.\n",
      "  Batch 5,880  of  41,827.    Elapsed: 0:35:48.\n",
      "  Batch 5,920  of  41,827.    Elapsed: 0:36:03.\n",
      "  Batch 5,960  of  41,827.    Elapsed: 0:36:17.\n",
      "  Batch 6,000  of  41,827.    Elapsed: 0:36:32.\n",
      "  Batch 6,040  of  41,827.    Elapsed: 0:36:47.\n",
      "  Batch 6,080  of  41,827.    Elapsed: 0:37:01.\n",
      "  Batch 6,120  of  41,827.    Elapsed: 0:37:16.\n",
      "  Batch 6,160  of  41,827.    Elapsed: 0:37:30.\n",
      "  Batch 6,200  of  41,827.    Elapsed: 0:37:45.\n",
      "  Batch 6,240  of  41,827.    Elapsed: 0:37:59.\n",
      "  Batch 6,280  of  41,827.    Elapsed: 0:38:14.\n",
      "  Batch 6,320  of  41,827.    Elapsed: 0:38:29.\n",
      "  Batch 6,360  of  41,827.    Elapsed: 0:38:43.\n",
      "  Batch 6,400  of  41,827.    Elapsed: 0:38:58.\n",
      "  Batch 6,440  of  41,827.    Elapsed: 0:39:13.\n",
      "  Batch 6,480  of  41,827.    Elapsed: 0:39:27.\n",
      "  Batch 6,520  of  41,827.    Elapsed: 0:39:42.\n",
      "  Batch 6,560  of  41,827.    Elapsed: 0:39:56.\n",
      "  Batch 6,600  of  41,827.    Elapsed: 0:40:11.\n",
      "  Batch 6,640  of  41,827.    Elapsed: 0:40:26.\n",
      "  Batch 6,680  of  41,827.    Elapsed: 0:40:40.\n",
      "  Batch 6,720  of  41,827.    Elapsed: 0:40:55.\n",
      "  Batch 6,760  of  41,827.    Elapsed: 0:41:10.\n",
      "  Batch 6,800  of  41,827.    Elapsed: 0:41:24.\n",
      "  Batch 6,840  of  41,827.    Elapsed: 0:41:39.\n",
      "  Batch 6,880  of  41,827.    Elapsed: 0:41:53.\n",
      "  Batch 6,920  of  41,827.    Elapsed: 0:42:08.\n",
      "  Batch 6,960  of  41,827.    Elapsed: 0:42:23.\n",
      "  Batch 7,000  of  41,827.    Elapsed: 0:42:37.\n",
      "  Batch 7,040  of  41,827.    Elapsed: 0:42:52.\n",
      "  Batch 7,080  of  41,827.    Elapsed: 0:43:06.\n",
      "  Batch 7,120  of  41,827.    Elapsed: 0:43:21.\n",
      "  Batch 7,160  of  41,827.    Elapsed: 0:43:36.\n",
      "  Batch 7,200  of  41,827.    Elapsed: 0:43:50.\n",
      "  Batch 7,240  of  41,827.    Elapsed: 0:44:05.\n",
      "  Batch 7,280  of  41,827.    Elapsed: 0:44:19.\n",
      "  Batch 7,320  of  41,827.    Elapsed: 0:44:34.\n",
      "  Batch 7,360  of  41,827.    Elapsed: 0:44:49.\n",
      "  Batch 7,400  of  41,827.    Elapsed: 0:45:03.\n",
      "  Batch 7,440  of  41,827.    Elapsed: 0:45:18.\n",
      "  Batch 7,480  of  41,827.    Elapsed: 0:45:32.\n",
      "  Batch 7,520  of  41,827.    Elapsed: 0:45:47.\n",
      "  Batch 7,560  of  41,827.    Elapsed: 0:46:02.\n",
      "  Batch 7,600  of  41,827.    Elapsed: 0:46:16.\n",
      "  Batch 7,640  of  41,827.    Elapsed: 0:46:31.\n",
      "  Batch 7,680  of  41,827.    Elapsed: 0:46:45.\n",
      "  Batch 7,720  of  41,827.    Elapsed: 0:47:00.\n",
      "  Batch 7,760  of  41,827.    Elapsed: 0:47:15.\n",
      "  Batch 7,800  of  41,827.    Elapsed: 0:47:29.\n",
      "  Batch 7,840  of  41,827.    Elapsed: 0:47:44.\n",
      "  Batch 7,880  of  41,827.    Elapsed: 0:47:59.\n",
      "  Batch 7,920  of  41,827.    Elapsed: 0:48:13.\n",
      "  Batch 7,960  of  41,827.    Elapsed: 0:48:28.\n",
      "  Batch 8,000  of  41,827.    Elapsed: 0:48:42.\n",
      "  Batch 8,040  of  41,827.    Elapsed: 0:48:57.\n",
      "  Batch 8,080  of  41,827.    Elapsed: 0:49:12.\n",
      "  Batch 8,120  of  41,827.    Elapsed: 0:49:26.\n",
      "  Batch 8,160  of  41,827.    Elapsed: 0:49:41.\n",
      "  Batch 8,200  of  41,827.    Elapsed: 0:49:56.\n",
      "  Batch 8,240  of  41,827.    Elapsed: 0:50:10.\n",
      "  Batch 8,280  of  41,827.    Elapsed: 0:50:25.\n",
      "  Batch 8,320  of  41,827.    Elapsed: 0:50:40.\n",
      "  Batch 8,360  of  41,827.    Elapsed: 0:50:54.\n",
      "  Batch 8,400  of  41,827.    Elapsed: 0:51:09.\n",
      "  Batch 8,440  of  41,827.    Elapsed: 0:51:24.\n",
      "  Batch 8,480  of  41,827.    Elapsed: 0:51:38.\n",
      "  Batch 8,520  of  41,827.    Elapsed: 0:51:53.\n",
      "  Batch 8,560  of  41,827.    Elapsed: 0:52:07.\n",
      "  Batch 8,600  of  41,827.    Elapsed: 0:52:22.\n",
      "  Batch 8,640  of  41,827.    Elapsed: 0:52:37.\n",
      "  Batch 8,680  of  41,827.    Elapsed: 0:52:51.\n",
      "  Batch 8,720  of  41,827.    Elapsed: 0:53:06.\n",
      "  Batch 8,760  of  41,827.    Elapsed: 0:53:21.\n",
      "  Batch 8,800  of  41,827.    Elapsed: 0:53:35.\n",
      "  Batch 8,840  of  41,827.    Elapsed: 0:53:50.\n",
      "  Batch 8,880  of  41,827.    Elapsed: 0:54:04.\n",
      "  Batch 8,920  of  41,827.    Elapsed: 0:54:19.\n",
      "  Batch 8,960  of  41,827.    Elapsed: 0:54:34.\n",
      "  Batch 9,000  of  41,827.    Elapsed: 0:54:48.\n",
      "  Batch 9,040  of  41,827.    Elapsed: 0:55:03.\n",
      "  Batch 9,080  of  41,827.    Elapsed: 0:55:18.\n",
      "  Batch 9,120  of  41,827.    Elapsed: 0:55:32.\n",
      "  Batch 9,160  of  41,827.    Elapsed: 0:55:47.\n",
      "  Batch 9,200  of  41,827.    Elapsed: 0:56:01.\n",
      "  Batch 9,240  of  41,827.    Elapsed: 0:56:16.\n",
      "  Batch 9,280  of  41,827.    Elapsed: 0:56:31.\n",
      "  Batch 9,320  of  41,827.    Elapsed: 0:56:45.\n",
      "  Batch 9,360  of  41,827.    Elapsed: 0:57:00.\n",
      "  Batch 9,400  of  41,827.    Elapsed: 0:57:14.\n",
      "  Batch 9,440  of  41,827.    Elapsed: 0:57:29.\n",
      "  Batch 9,480  of  41,827.    Elapsed: 0:57:44.\n",
      "  Batch 9,520  of  41,827.    Elapsed: 0:57:58.\n",
      "  Batch 9,560  of  41,827.    Elapsed: 0:58:13.\n",
      "  Batch 9,600  of  41,827.    Elapsed: 0:58:27.\n",
      "  Batch 9,640  of  41,827.    Elapsed: 0:58:42.\n",
      "  Batch 9,680  of  41,827.    Elapsed: 0:58:57.\n",
      "  Batch 9,720  of  41,827.    Elapsed: 0:59:11.\n",
      "  Batch 9,760  of  41,827.    Elapsed: 0:59:26.\n",
      "  Batch 9,800  of  41,827.    Elapsed: 0:59:40.\n",
      "  Batch 9,840  of  41,827.    Elapsed: 0:59:55.\n",
      "  Batch 9,880  of  41,827.    Elapsed: 1:00:10.\n",
      "  Batch 9,920  of  41,827.    Elapsed: 1:00:24.\n",
      "  Batch 9,960  of  41,827.    Elapsed: 1:00:39.\n",
      "  Batch 10,000  of  41,827.    Elapsed: 1:00:53.\n",
      "  Batch 10,040  of  41,827.    Elapsed: 1:01:08.\n",
      "  Batch 10,080  of  41,827.    Elapsed: 1:01:23.\n",
      "  Batch 10,120  of  41,827.    Elapsed: 1:01:37.\n",
      "  Batch 10,160  of  41,827.    Elapsed: 1:01:52.\n",
      "  Batch 10,200  of  41,827.    Elapsed: 1:02:06.\n",
      "  Batch 10,240  of  41,827.    Elapsed: 1:02:21.\n",
      "  Batch 10,280  of  41,827.    Elapsed: 1:02:36.\n",
      "  Batch 10,320  of  41,827.    Elapsed: 1:02:50.\n",
      "  Batch 10,360  of  41,827.    Elapsed: 1:03:05.\n",
      "  Batch 10,400  of  41,827.    Elapsed: 1:03:20.\n",
      "  Batch 10,440  of  41,827.    Elapsed: 1:03:34.\n",
      "  Batch 10,480  of  41,827.    Elapsed: 1:03:49.\n",
      "  Batch 10,520  of  41,827.    Elapsed: 1:04:03.\n",
      "  Batch 10,560  of  41,827.    Elapsed: 1:04:18.\n",
      "  Batch 10,600  of  41,827.    Elapsed: 1:04:33.\n",
      "  Batch 10,640  of  41,827.    Elapsed: 1:04:47.\n",
      "  Batch 10,680  of  41,827.    Elapsed: 1:05:02.\n",
      "  Batch 10,720  of  41,827.    Elapsed: 1:05:16.\n",
      "  Batch 10,760  of  41,827.    Elapsed: 1:05:31.\n",
      "  Batch 10,800  of  41,827.    Elapsed: 1:05:46.\n",
      "  Batch 10,840  of  41,827.    Elapsed: 1:06:00.\n",
      "  Batch 10,880  of  41,827.    Elapsed: 1:06:15.\n",
      "  Batch 10,920  of  41,827.    Elapsed: 1:06:30.\n",
      "  Batch 10,960  of  41,827.    Elapsed: 1:06:44.\n",
      "  Batch 11,000  of  41,827.    Elapsed: 1:06:59.\n",
      "  Batch 11,040  of  41,827.    Elapsed: 1:07:13.\n",
      "  Batch 11,080  of  41,827.    Elapsed: 1:07:28.\n",
      "  Batch 11,120  of  41,827.    Elapsed: 1:07:43.\n",
      "  Batch 11,160  of  41,827.    Elapsed: 1:07:57.\n",
      "  Batch 11,200  of  41,827.    Elapsed: 1:08:12.\n",
      "  Batch 11,240  of  41,827.    Elapsed: 1:08:26.\n",
      "  Batch 11,280  of  41,827.    Elapsed: 1:08:41.\n",
      "  Batch 11,320  of  41,827.    Elapsed: 1:08:56.\n",
      "  Batch 11,360  of  41,827.    Elapsed: 1:09:10.\n",
      "  Batch 11,400  of  41,827.    Elapsed: 1:09:25.\n",
      "  Batch 11,440  of  41,827.    Elapsed: 1:09:39.\n",
      "  Batch 11,480  of  41,827.    Elapsed: 1:09:54.\n",
      "  Batch 11,520  of  41,827.    Elapsed: 1:10:09.\n",
      "  Batch 11,560  of  41,827.    Elapsed: 1:10:23.\n",
      "  Batch 11,600  of  41,827.    Elapsed: 1:10:38.\n",
      "  Batch 11,640  of  41,827.    Elapsed: 1:10:52.\n",
      "  Batch 11,680  of  41,827.    Elapsed: 1:11:07.\n",
      "  Batch 11,720  of  41,827.    Elapsed: 1:11:22.\n",
      "  Batch 11,760  of  41,827.    Elapsed: 1:11:36.\n",
      "  Batch 11,800  of  41,827.    Elapsed: 1:11:51.\n",
      "  Batch 11,840  of  41,827.    Elapsed: 1:12:05.\n",
      "  Batch 11,880  of  41,827.    Elapsed: 1:12:20.\n",
      "  Batch 11,920  of  41,827.    Elapsed: 1:12:35.\n",
      "  Batch 11,960  of  41,827.    Elapsed: 1:12:49.\n",
      "  Batch 12,000  of  41,827.    Elapsed: 1:13:04.\n",
      "  Batch 12,040  of  41,827.    Elapsed: 1:13:18.\n",
      "  Batch 12,080  of  41,827.    Elapsed: 1:13:33.\n",
      "  Batch 12,120  of  41,827.    Elapsed: 1:13:48.\n",
      "  Batch 12,160  of  41,827.    Elapsed: 1:14:02.\n",
      "  Batch 12,200  of  41,827.    Elapsed: 1:14:17.\n",
      "  Batch 12,240  of  41,827.    Elapsed: 1:14:32.\n",
      "  Batch 12,280  of  41,827.    Elapsed: 1:14:46.\n",
      "  Batch 12,320  of  41,827.    Elapsed: 1:15:01.\n",
      "  Batch 12,360  of  41,827.    Elapsed: 1:15:15.\n",
      "  Batch 12,400  of  41,827.    Elapsed: 1:15:30.\n",
      "  Batch 12,440  of  41,827.    Elapsed: 1:15:45.\n",
      "  Batch 12,480  of  41,827.    Elapsed: 1:15:59.\n",
      "  Batch 12,520  of  41,827.    Elapsed: 1:16:14.\n",
      "  Batch 12,560  of  41,827.    Elapsed: 1:16:28.\n",
      "  Batch 12,600  of  41,827.    Elapsed: 1:16:43.\n",
      "  Batch 12,640  of  41,827.    Elapsed: 1:16:58.\n",
      "  Batch 12,680  of  41,827.    Elapsed: 1:17:12.\n",
      "  Batch 12,720  of  41,827.    Elapsed: 1:17:27.\n",
      "  Batch 12,760  of  41,827.    Elapsed: 1:17:41.\n",
      "  Batch 12,800  of  41,827.    Elapsed: 1:17:56.\n",
      "  Batch 12,840  of  41,827.    Elapsed: 1:18:11.\n",
      "  Batch 12,880  of  41,827.    Elapsed: 1:18:25.\n",
      "  Batch 12,920  of  41,827.    Elapsed: 1:18:40.\n",
      "  Batch 12,960  of  41,827.    Elapsed: 1:18:54.\n",
      "  Batch 13,000  of  41,827.    Elapsed: 1:19:09.\n",
      "  Batch 13,040  of  41,827.    Elapsed: 1:19:24.\n",
      "  Batch 13,080  of  41,827.    Elapsed: 1:19:38.\n",
      "  Batch 13,120  of  41,827.    Elapsed: 1:19:53.\n",
      "  Batch 13,160  of  41,827.    Elapsed: 1:20:07.\n",
      "  Batch 13,200  of  41,827.    Elapsed: 1:20:22.\n",
      "  Batch 13,240  of  41,827.    Elapsed: 1:20:37.\n",
      "  Batch 13,280  of  41,827.    Elapsed: 1:20:51.\n",
      "  Batch 13,320  of  41,827.    Elapsed: 1:21:06.\n",
      "  Batch 13,360  of  41,827.    Elapsed: 1:21:20.\n",
      "  Batch 13,400  of  41,827.    Elapsed: 1:21:35.\n",
      "  Batch 13,440  of  41,827.    Elapsed: 1:21:50.\n",
      "  Batch 13,480  of  41,827.    Elapsed: 1:22:04.\n",
      "  Batch 13,520  of  41,827.    Elapsed: 1:22:19.\n",
      "  Batch 13,560  of  41,827.    Elapsed: 1:22:33.\n",
      "  Batch 13,600  of  41,827.    Elapsed: 1:22:48.\n",
      "  Batch 13,640  of  41,827.    Elapsed: 1:23:03.\n",
      "  Batch 13,680  of  41,827.    Elapsed: 1:23:17.\n",
      "  Batch 13,720  of  41,827.    Elapsed: 1:23:32.\n",
      "  Batch 13,760  of  41,827.    Elapsed: 1:23:46.\n",
      "  Batch 13,800  of  41,827.    Elapsed: 1:24:01.\n",
      "  Batch 13,840  of  41,827.    Elapsed: 1:24:16.\n",
      "  Batch 13,880  of  41,827.    Elapsed: 1:24:30.\n",
      "  Batch 13,920  of  41,827.    Elapsed: 1:24:45.\n",
      "  Batch 13,960  of  41,827.    Elapsed: 1:24:59.\n",
      "  Batch 14,000  of  41,827.    Elapsed: 1:25:14.\n",
      "  Batch 14,040  of  41,827.    Elapsed: 1:25:29.\n",
      "  Batch 14,080  of  41,827.    Elapsed: 1:25:43.\n",
      "  Batch 14,120  of  41,827.    Elapsed: 1:25:58.\n",
      "  Batch 14,160  of  41,827.    Elapsed: 1:26:12.\n",
      "  Batch 14,200  of  41,827.    Elapsed: 1:26:27.\n",
      "  Batch 14,240  of  41,827.    Elapsed: 1:26:42.\n",
      "  Batch 14,280  of  41,827.    Elapsed: 1:26:56.\n",
      "  Batch 14,320  of  41,827.    Elapsed: 1:27:11.\n",
      "  Batch 14,360  of  41,827.    Elapsed: 1:27:25.\n",
      "  Batch 14,400  of  41,827.    Elapsed: 1:27:40.\n",
      "  Batch 14,440  of  41,827.    Elapsed: 1:27:55.\n",
      "  Batch 14,480  of  41,827.    Elapsed: 1:28:09.\n",
      "  Batch 14,520  of  41,827.    Elapsed: 1:28:24.\n",
      "  Batch 14,560  of  41,827.    Elapsed: 1:28:38.\n",
      "  Batch 14,600  of  41,827.    Elapsed: 1:28:53.\n",
      "  Batch 14,640  of  41,827.    Elapsed: 1:29:08.\n",
      "  Batch 14,680  of  41,827.    Elapsed: 1:29:22.\n",
      "  Batch 14,720  of  41,827.    Elapsed: 1:29:37.\n",
      "  Batch 14,760  of  41,827.    Elapsed: 1:29:51.\n",
      "  Batch 14,800  of  41,827.    Elapsed: 1:30:06.\n",
      "  Batch 14,840  of  41,827.    Elapsed: 1:30:21.\n",
      "  Batch 14,880  of  41,827.    Elapsed: 1:30:35.\n",
      "  Batch 14,920  of  41,827.    Elapsed: 1:30:50.\n",
      "  Batch 14,960  of  41,827.    Elapsed: 1:31:04.\n",
      "  Batch 15,000  of  41,827.    Elapsed: 1:31:19.\n",
      "  Batch 15,040  of  41,827.    Elapsed: 1:31:34.\n",
      "  Batch 15,080  of  41,827.    Elapsed: 1:31:48.\n",
      "  Batch 15,120  of  41,827.    Elapsed: 1:32:03.\n",
      "  Batch 15,160  of  41,827.    Elapsed: 1:32:18.\n",
      "  Batch 15,200  of  41,827.    Elapsed: 1:32:32.\n",
      "  Batch 15,240  of  41,827.    Elapsed: 1:32:47.\n",
      "  Batch 15,280  of  41,827.    Elapsed: 1:33:01.\n",
      "  Batch 15,320  of  41,827.    Elapsed: 1:33:16.\n",
      "  Batch 15,360  of  41,827.    Elapsed: 1:33:31.\n",
      "  Batch 15,400  of  41,827.    Elapsed: 1:33:45.\n",
      "  Batch 15,440  of  41,827.    Elapsed: 1:34:00.\n",
      "  Batch 15,480  of  41,827.    Elapsed: 1:34:14.\n",
      "  Batch 15,520  of  41,827.    Elapsed: 1:34:29.\n",
      "  Batch 15,560  of  41,827.    Elapsed: 1:34:44.\n",
      "  Batch 15,600  of  41,827.    Elapsed: 1:34:58.\n",
      "  Batch 15,640  of  41,827.    Elapsed: 1:35:13.\n",
      "  Batch 15,680  of  41,827.    Elapsed: 1:35:27.\n",
      "  Batch 15,720  of  41,827.    Elapsed: 1:35:42.\n",
      "  Batch 15,760  of  41,827.    Elapsed: 1:35:57.\n",
      "  Batch 15,800  of  41,827.    Elapsed: 1:36:11.\n",
      "  Batch 15,840  of  41,827.    Elapsed: 1:36:26.\n",
      "  Batch 15,880  of  41,827.    Elapsed: 1:36:40.\n",
      "  Batch 15,920  of  41,827.    Elapsed: 1:36:55.\n",
      "  Batch 15,960  of  41,827.    Elapsed: 1:37:10.\n",
      "  Batch 16,000  of  41,827.    Elapsed: 1:37:24.\n",
      "  Batch 16,040  of  41,827.    Elapsed: 1:37:39.\n",
      "  Batch 16,080  of  41,827.    Elapsed: 1:37:53.\n",
      "  Batch 16,120  of  41,827.    Elapsed: 1:38:08.\n",
      "  Batch 16,160  of  41,827.    Elapsed: 1:38:23.\n",
      "  Batch 16,200  of  41,827.    Elapsed: 1:38:37.\n",
      "  Batch 16,240  of  41,827.    Elapsed: 1:38:52.\n",
      "  Batch 16,280  of  41,827.    Elapsed: 1:39:06.\n",
      "  Batch 16,320  of  41,827.    Elapsed: 1:39:21.\n",
      "  Batch 16,360  of  41,827.    Elapsed: 1:39:36.\n",
      "  Batch 16,400  of  41,827.    Elapsed: 1:39:50.\n",
      "  Batch 16,440  of  41,827.    Elapsed: 1:40:05.\n",
      "  Batch 16,480  of  41,827.    Elapsed: 1:40:19.\n",
      "  Batch 16,520  of  41,827.    Elapsed: 1:40:34.\n",
      "  Batch 16,560  of  41,827.    Elapsed: 1:40:49.\n",
      "  Batch 16,600  of  41,827.    Elapsed: 1:41:03.\n",
      "  Batch 16,640  of  41,827.    Elapsed: 1:41:18.\n",
      "  Batch 16,680  of  41,827.    Elapsed: 1:41:32.\n",
      "  Batch 16,720  of  41,827.    Elapsed: 1:41:47.\n",
      "  Batch 16,760  of  41,827.    Elapsed: 1:42:02.\n",
      "  Batch 16,800  of  41,827.    Elapsed: 1:42:16.\n",
      "  Batch 16,840  of  41,827.    Elapsed: 1:42:31.\n",
      "  Batch 16,880  of  41,827.    Elapsed: 1:42:45.\n",
      "  Batch 16,920  of  41,827.    Elapsed: 1:43:00.\n",
      "  Batch 16,960  of  41,827.    Elapsed: 1:43:15.\n",
      "  Batch 17,000  of  41,827.    Elapsed: 1:43:29.\n",
      "  Batch 17,040  of  41,827.    Elapsed: 1:43:44.\n",
      "  Batch 17,080  of  41,827.    Elapsed: 1:43:58.\n",
      "  Batch 17,120  of  41,827.    Elapsed: 1:44:13.\n",
      "  Batch 17,160  of  41,827.    Elapsed: 1:44:28.\n",
      "  Batch 17,200  of  41,827.    Elapsed: 1:44:42.\n",
      "  Batch 17,240  of  41,827.    Elapsed: 1:44:57.\n",
      "  Batch 17,280  of  41,827.    Elapsed: 1:45:11.\n",
      "  Batch 17,320  of  41,827.    Elapsed: 1:45:26.\n",
      "  Batch 17,360  of  41,827.    Elapsed: 1:45:41.\n",
      "  Batch 17,400  of  41,827.    Elapsed: 1:45:55.\n",
      "  Batch 17,440  of  41,827.    Elapsed: 1:46:10.\n",
      "  Batch 17,480  of  41,827.    Elapsed: 1:46:25.\n",
      "  Batch 17,520  of  41,827.    Elapsed: 1:46:39.\n",
      "  Batch 17,560  of  41,827.    Elapsed: 1:46:54.\n",
      "  Batch 17,600  of  41,827.    Elapsed: 1:47:08.\n",
      "  Batch 17,640  of  41,827.    Elapsed: 1:47:23.\n",
      "  Batch 17,680  of  41,827.    Elapsed: 1:47:38.\n",
      "  Batch 17,720  of  41,827.    Elapsed: 1:47:52.\n",
      "  Batch 17,760  of  41,827.    Elapsed: 1:48:07.\n",
      "  Batch 17,800  of  41,827.    Elapsed: 1:48:21.\n",
      "  Batch 17,840  of  41,827.    Elapsed: 1:48:36.\n",
      "  Batch 17,880  of  41,827.    Elapsed: 1:48:51.\n",
      "  Batch 17,920  of  41,827.    Elapsed: 1:49:05.\n",
      "  Batch 17,960  of  41,827.    Elapsed: 1:49:20.\n",
      "  Batch 18,000  of  41,827.    Elapsed: 1:49:35.\n",
      "  Batch 18,040  of  41,827.    Elapsed: 1:49:49.\n",
      "  Batch 18,080  of  41,827.    Elapsed: 1:50:04.\n",
      "  Batch 18,120  of  41,827.    Elapsed: 1:50:18.\n",
      "  Batch 18,160  of  41,827.    Elapsed: 1:50:33.\n",
      "  Batch 18,200  of  41,827.    Elapsed: 1:50:48.\n",
      "  Batch 18,240  of  41,827.    Elapsed: 1:51:02.\n",
      "  Batch 18,280  of  41,827.    Elapsed: 1:51:17.\n",
      "  Batch 18,320  of  41,827.    Elapsed: 1:51:32.\n",
      "  Batch 18,360  of  41,827.    Elapsed: 1:51:46.\n",
      "  Batch 18,400  of  41,827.    Elapsed: 1:52:01.\n",
      "  Batch 18,440  of  41,827.    Elapsed: 1:52:16.\n",
      "  Batch 18,480  of  41,827.    Elapsed: 1:52:30.\n",
      "  Batch 18,520  of  41,827.    Elapsed: 1:52:45.\n",
      "  Batch 18,560  of  41,827.    Elapsed: 1:52:59.\n",
      "  Batch 18,600  of  41,827.    Elapsed: 1:53:14.\n",
      "  Batch 18,640  of  41,827.    Elapsed: 1:53:29.\n",
      "  Batch 18,680  of  41,827.    Elapsed: 1:53:43.\n",
      "  Batch 18,720  of  41,827.    Elapsed: 1:53:58.\n",
      "  Batch 18,760  of  41,827.    Elapsed: 1:54:12.\n",
      "  Batch 18,800  of  41,827.    Elapsed: 1:54:27.\n",
      "  Batch 18,840  of  41,827.    Elapsed: 1:54:42.\n",
      "  Batch 18,880  of  41,827.    Elapsed: 1:54:56.\n",
      "  Batch 18,920  of  41,827.    Elapsed: 1:55:11.\n",
      "  Batch 18,960  of  41,827.    Elapsed: 1:55:25.\n",
      "  Batch 19,000  of  41,827.    Elapsed: 1:55:40.\n",
      "  Batch 19,040  of  41,827.    Elapsed: 1:55:55.\n",
      "  Batch 19,080  of  41,827.    Elapsed: 1:56:09.\n",
      "  Batch 19,120  of  41,827.    Elapsed: 1:56:24.\n",
      "  Batch 19,160  of  41,827.    Elapsed: 1:56:38.\n",
      "  Batch 19,200  of  41,827.    Elapsed: 1:56:53.\n",
      "  Batch 19,240  of  41,827.    Elapsed: 1:57:08.\n",
      "  Batch 19,280  of  41,827.    Elapsed: 1:57:22.\n",
      "  Batch 19,320  of  41,827.    Elapsed: 1:57:37.\n",
      "  Batch 19,360  of  41,827.    Elapsed: 1:57:51.\n",
      "  Batch 19,400  of  41,827.    Elapsed: 1:58:06.\n",
      "  Batch 19,440  of  41,827.    Elapsed: 1:58:21.\n",
      "  Batch 19,480  of  41,827.    Elapsed: 1:58:35.\n",
      "  Batch 19,520  of  41,827.    Elapsed: 1:58:50.\n",
      "  Batch 19,560  of  41,827.    Elapsed: 1:59:04.\n",
      "  Batch 19,600  of  41,827.    Elapsed: 1:59:19.\n",
      "  Batch 19,640  of  41,827.    Elapsed: 1:59:34.\n",
      "  Batch 19,680  of  41,827.    Elapsed: 1:59:48.\n",
      "  Batch 19,720  of  41,827.    Elapsed: 2:00:03.\n",
      "  Batch 19,760  of  41,827.    Elapsed: 2:00:17.\n",
      "  Batch 19,800  of  41,827.    Elapsed: 2:00:32.\n",
      "  Batch 19,840  of  41,827.    Elapsed: 2:00:47.\n",
      "  Batch 19,880  of  41,827.    Elapsed: 2:01:01.\n",
      "  Batch 19,920  of  41,827.    Elapsed: 2:01:16.\n",
      "  Batch 19,960  of  41,827.    Elapsed: 2:01:30.\n",
      "  Batch 20,000  of  41,827.    Elapsed: 2:01:45.\n",
      "  Batch 20,040  of  41,827.    Elapsed: 2:01:59.\n",
      "  Batch 20,080  of  41,827.    Elapsed: 2:02:14.\n",
      "  Batch 20,120  of  41,827.    Elapsed: 2:02:29.\n",
      "  Batch 20,160  of  41,827.    Elapsed: 2:02:43.\n",
      "  Batch 20,200  of  41,827.    Elapsed: 2:02:58.\n",
      "  Batch 20,240  of  41,827.    Elapsed: 2:03:12.\n",
      "  Batch 20,280  of  41,827.    Elapsed: 2:03:27.\n",
      "  Batch 20,320  of  41,827.    Elapsed: 2:03:42.\n",
      "  Batch 20,360  of  41,827.    Elapsed: 2:03:56.\n",
      "  Batch 20,400  of  41,827.    Elapsed: 2:04:11.\n",
      "  Batch 20,440  of  41,827.    Elapsed: 2:04:25.\n",
      "  Batch 20,480  of  41,827.    Elapsed: 2:04:40.\n",
      "  Batch 20,520  of  41,827.    Elapsed: 2:04:54.\n",
      "  Batch 20,560  of  41,827.    Elapsed: 2:05:09.\n",
      "  Batch 20,600  of  41,827.    Elapsed: 2:05:24.\n",
      "  Batch 20,640  of  41,827.    Elapsed: 2:05:38.\n",
      "  Batch 20,680  of  41,827.    Elapsed: 2:05:53.\n",
      "  Batch 20,720  of  41,827.    Elapsed: 2:06:07.\n",
      "  Batch 20,760  of  41,827.    Elapsed: 2:06:22.\n",
      "  Batch 20,800  of  41,827.    Elapsed: 2:06:36.\n",
      "  Batch 20,840  of  41,827.    Elapsed: 2:06:51.\n",
      "  Batch 20,880  of  41,827.    Elapsed: 2:07:06.\n",
      "  Batch 20,920  of  41,827.    Elapsed: 2:07:20.\n",
      "  Batch 20,960  of  41,827.    Elapsed: 2:07:35.\n",
      "  Batch 21,000  of  41,827.    Elapsed: 2:07:49.\n",
      "  Batch 21,040  of  41,827.    Elapsed: 2:08:04.\n",
      "  Batch 21,080  of  41,827.    Elapsed: 2:08:18.\n",
      "  Batch 21,120  of  41,827.    Elapsed: 2:08:33.\n",
      "  Batch 21,160  of  41,827.    Elapsed: 2:08:48.\n",
      "  Batch 21,200  of  41,827.    Elapsed: 2:09:02.\n",
      "  Batch 21,240  of  41,827.    Elapsed: 2:09:17.\n",
      "  Batch 21,280  of  41,827.    Elapsed: 2:09:31.\n",
      "  Batch 21,320  of  41,827.    Elapsed: 2:09:46.\n",
      "  Batch 21,360  of  41,827.    Elapsed: 2:10:00.\n",
      "  Batch 21,400  of  41,827.    Elapsed: 2:10:15.\n",
      "  Batch 21,440  of  41,827.    Elapsed: 2:10:29.\n",
      "  Batch 21,480  of  41,827.    Elapsed: 2:10:44.\n",
      "  Batch 21,520  of  41,827.    Elapsed: 2:10:59.\n",
      "  Batch 21,560  of  41,827.    Elapsed: 2:11:13.\n",
      "  Batch 21,600  of  41,827.    Elapsed: 2:11:28.\n",
      "  Batch 21,640  of  41,827.    Elapsed: 2:11:42.\n",
      "  Batch 21,680  of  41,827.    Elapsed: 2:11:57.\n",
      "  Batch 21,720  of  41,827.    Elapsed: 2:12:11.\n",
      "  Batch 21,760  of  41,827.    Elapsed: 2:12:26.\n",
      "  Batch 21,800  of  41,827.    Elapsed: 2:12:41.\n",
      "  Batch 21,840  of  41,827.    Elapsed: 2:12:55.\n",
      "  Batch 21,880  of  41,827.    Elapsed: 2:13:10.\n",
      "  Batch 21,920  of  41,827.    Elapsed: 2:13:24.\n",
      "  Batch 21,960  of  41,827.    Elapsed: 2:13:39.\n",
      "  Batch 22,000  of  41,827.    Elapsed: 2:13:53.\n",
      "  Batch 22,040  of  41,827.    Elapsed: 2:14:08.\n",
      "  Batch 22,080  of  41,827.    Elapsed: 2:14:23.\n",
      "  Batch 22,120  of  41,827.    Elapsed: 2:14:37.\n",
      "  Batch 22,160  of  41,827.    Elapsed: 2:14:52.\n",
      "  Batch 22,200  of  41,827.    Elapsed: 2:15:06.\n",
      "  Batch 22,240  of  41,827.    Elapsed: 2:15:21.\n",
      "  Batch 22,280  of  41,827.    Elapsed: 2:15:35.\n",
      "  Batch 22,320  of  41,827.    Elapsed: 2:15:50.\n",
      "  Batch 22,360  of  41,827.    Elapsed: 2:16:04.\n",
      "  Batch 22,400  of  41,827.    Elapsed: 2:16:19.\n",
      "  Batch 22,440  of  41,827.    Elapsed: 2:16:34.\n",
      "  Batch 22,480  of  41,827.    Elapsed: 2:16:48.\n",
      "  Batch 22,520  of  41,827.    Elapsed: 2:17:03.\n",
      "  Batch 22,560  of  41,827.    Elapsed: 2:17:17.\n",
      "  Batch 22,600  of  41,827.    Elapsed: 2:17:32.\n",
      "  Batch 22,640  of  41,827.    Elapsed: 2:17:47.\n",
      "  Batch 22,680  of  41,827.    Elapsed: 2:18:01.\n",
      "  Batch 22,720  of  41,827.    Elapsed: 2:18:16.\n",
      "  Batch 22,760  of  41,827.    Elapsed: 2:18:30.\n",
      "  Batch 22,800  of  41,827.    Elapsed: 2:18:45.\n",
      "  Batch 22,840  of  41,827.    Elapsed: 2:18:59.\n",
      "  Batch 22,880  of  41,827.    Elapsed: 2:19:14.\n",
      "  Batch 22,920  of  41,827.    Elapsed: 2:19:29.\n",
      "  Batch 22,960  of  41,827.    Elapsed: 2:19:43.\n",
      "  Batch 23,000  of  41,827.    Elapsed: 2:19:58.\n",
      "  Batch 23,040  of  41,827.    Elapsed: 2:20:12.\n",
      "  Batch 23,080  of  41,827.    Elapsed: 2:20:27.\n",
      "  Batch 23,120  of  41,827.    Elapsed: 2:20:42.\n",
      "  Batch 23,160  of  41,827.    Elapsed: 2:20:56.\n",
      "  Batch 23,200  of  41,827.    Elapsed: 2:21:11.\n",
      "  Batch 23,240  of  41,827.    Elapsed: 2:21:25.\n",
      "  Batch 23,280  of  41,827.    Elapsed: 2:21:40.\n",
      "  Batch 23,320  of  41,827.    Elapsed: 2:21:54.\n",
      "  Batch 23,360  of  41,827.    Elapsed: 2:22:09.\n",
      "  Batch 23,400  of  41,827.    Elapsed: 2:22:24.\n",
      "  Batch 23,440  of  41,827.    Elapsed: 2:22:38.\n",
      "  Batch 23,480  of  41,827.    Elapsed: 2:22:53.\n",
      "  Batch 23,520  of  41,827.    Elapsed: 2:23:07.\n",
      "  Batch 23,560  of  41,827.    Elapsed: 2:23:22.\n",
      "  Batch 23,600  of  41,827.    Elapsed: 2:23:36.\n",
      "  Batch 23,640  of  41,827.    Elapsed: 2:23:51.\n",
      "  Batch 23,680  of  41,827.    Elapsed: 2:24:06.\n",
      "  Batch 23,720  of  41,827.    Elapsed: 2:24:20.\n",
      "  Batch 23,760  of  41,827.    Elapsed: 2:24:35.\n",
      "  Batch 23,800  of  41,827.    Elapsed: 2:24:49.\n",
      "  Batch 23,840  of  41,827.    Elapsed: 2:25:04.\n",
      "  Batch 23,880  of  41,827.    Elapsed: 2:25:19.\n",
      "  Batch 23,920  of  41,827.    Elapsed: 2:25:33.\n",
      "  Batch 23,960  of  41,827.    Elapsed: 2:25:48.\n",
      "  Batch 24,000  of  41,827.    Elapsed: 2:26:02.\n",
      "  Batch 24,040  of  41,827.    Elapsed: 2:26:17.\n",
      "  Batch 24,080  of  41,827.    Elapsed: 2:26:32.\n",
      "  Batch 24,120  of  41,827.    Elapsed: 2:26:46.\n",
      "  Batch 24,160  of  41,827.    Elapsed: 2:27:01.\n",
      "  Batch 24,200  of  41,827.    Elapsed: 2:27:15.\n",
      "  Batch 24,240  of  41,827.    Elapsed: 2:27:30.\n",
      "  Batch 24,280  of  41,827.    Elapsed: 2:27:45.\n",
      "  Batch 24,320  of  41,827.    Elapsed: 2:27:59.\n",
      "  Batch 24,360  of  41,827.    Elapsed: 2:28:14.\n",
      "  Batch 24,400  of  41,827.    Elapsed: 2:28:28.\n",
      "  Batch 24,440  of  41,827.    Elapsed: 2:28:43.\n",
      "  Batch 24,480  of  41,827.    Elapsed: 2:28:58.\n",
      "  Batch 24,520  of  41,827.    Elapsed: 2:29:12.\n",
      "  Batch 24,560  of  41,827.    Elapsed: 2:29:27.\n",
      "  Batch 24,600  of  41,827.    Elapsed: 2:29:41.\n",
      "  Batch 24,640  of  41,827.    Elapsed: 2:29:56.\n",
      "  Batch 24,680  of  41,827.    Elapsed: 2:30:10.\n",
      "  Batch 24,720  of  41,827.    Elapsed: 2:30:25.\n",
      "  Batch 24,760  of  41,827.    Elapsed: 2:30:40.\n",
      "  Batch 24,800  of  41,827.    Elapsed: 2:30:54.\n",
      "  Batch 24,840  of  41,827.    Elapsed: 2:31:09.\n",
      "  Batch 24,880  of  41,827.    Elapsed: 2:31:23.\n",
      "  Batch 24,920  of  41,827.    Elapsed: 2:31:38.\n",
      "  Batch 24,960  of  41,827.    Elapsed: 2:31:53.\n",
      "  Batch 25,000  of  41,827.    Elapsed: 2:32:07.\n",
      "  Batch 25,040  of  41,827.    Elapsed: 2:32:22.\n",
      "  Batch 25,080  of  41,827.    Elapsed: 2:32:36.\n",
      "  Batch 25,120  of  41,827.    Elapsed: 2:32:51.\n",
      "  Batch 25,160  of  41,827.    Elapsed: 2:33:05.\n",
      "  Batch 25,200  of  41,827.    Elapsed: 2:33:20.\n",
      "  Batch 25,240  of  41,827.    Elapsed: 2:33:35.\n",
      "  Batch 25,280  of  41,827.    Elapsed: 2:33:49.\n",
      "  Batch 25,320  of  41,827.    Elapsed: 2:34:04.\n",
      "  Batch 25,360  of  41,827.    Elapsed: 2:34:18.\n",
      "  Batch 25,400  of  41,827.    Elapsed: 2:34:33.\n",
      "  Batch 25,440  of  41,827.    Elapsed: 2:34:47.\n",
      "  Batch 25,480  of  41,827.    Elapsed: 2:35:02.\n",
      "  Batch 25,520  of  41,827.    Elapsed: 2:35:17.\n",
      "  Batch 25,560  of  41,827.    Elapsed: 2:35:31.\n",
      "  Batch 25,600  of  41,827.    Elapsed: 2:35:46.\n",
      "  Batch 25,640  of  41,827.    Elapsed: 2:36:00.\n",
      "  Batch 25,680  of  41,827.    Elapsed: 2:36:15.\n",
      "  Batch 25,720  of  41,827.    Elapsed: 2:36:29.\n",
      "  Batch 25,760  of  41,827.    Elapsed: 2:36:44.\n",
      "  Batch 25,800  of  41,827.    Elapsed: 2:36:58.\n",
      "  Batch 25,840  of  41,827.    Elapsed: 2:37:13.\n",
      "  Batch 25,880  of  41,827.    Elapsed: 2:37:28.\n",
      "  Batch 25,920  of  41,827.    Elapsed: 2:37:42.\n",
      "  Batch 25,960  of  41,827.    Elapsed: 2:37:57.\n",
      "  Batch 26,000  of  41,827.    Elapsed: 2:38:11.\n",
      "  Batch 26,040  of  41,827.    Elapsed: 2:38:26.\n",
      "  Batch 26,080  of  41,827.    Elapsed: 2:38:40.\n",
      "  Batch 26,120  of  41,827.    Elapsed: 2:38:55.\n",
      "  Batch 26,160  of  41,827.    Elapsed: 2:39:10.\n",
      "  Batch 26,200  of  41,827.    Elapsed: 2:39:24.\n",
      "  Batch 26,240  of  41,827.    Elapsed: 2:39:39.\n",
      "  Batch 26,280  of  41,827.    Elapsed: 2:39:53.\n",
      "  Batch 26,320  of  41,827.    Elapsed: 2:40:08.\n",
      "  Batch 26,360  of  41,827.    Elapsed: 2:40:22.\n",
      "  Batch 26,400  of  41,827.    Elapsed: 2:40:37.\n",
      "  Batch 26,440  of  41,827.    Elapsed: 2:40:52.\n",
      "  Batch 26,480  of  41,827.    Elapsed: 2:41:06.\n",
      "  Batch 26,520  of  41,827.    Elapsed: 2:41:21.\n",
      "  Batch 26,560  of  41,827.    Elapsed: 2:41:35.\n",
      "  Batch 26,600  of  41,827.    Elapsed: 2:41:50.\n",
      "  Batch 26,640  of  41,827.    Elapsed: 2:42:04.\n",
      "  Batch 26,680  of  41,827.    Elapsed: 2:42:19.\n",
      "  Batch 26,720  of  41,827.    Elapsed: 2:42:34.\n",
      "  Batch 26,760  of  41,827.    Elapsed: 2:42:48.\n",
      "  Batch 26,800  of  41,827.    Elapsed: 2:43:03.\n",
      "  Batch 26,840  of  41,827.    Elapsed: 2:43:17.\n",
      "  Batch 26,880  of  41,827.    Elapsed: 2:43:32.\n",
      "  Batch 26,920  of  41,827.    Elapsed: 2:43:47.\n",
      "  Batch 26,960  of  41,827.    Elapsed: 2:44:01.\n",
      "  Batch 27,000  of  41,827.    Elapsed: 2:44:16.\n",
      "  Batch 27,040  of  41,827.    Elapsed: 2:44:30.\n",
      "  Batch 27,080  of  41,827.    Elapsed: 2:44:45.\n",
      "  Batch 27,120  of  41,827.    Elapsed: 2:44:59.\n",
      "  Batch 27,160  of  41,827.    Elapsed: 2:45:14.\n",
      "  Batch 27,200  of  41,827.    Elapsed: 2:45:29.\n",
      "  Batch 27,240  of  41,827.    Elapsed: 2:45:43.\n",
      "  Batch 27,280  of  41,827.    Elapsed: 2:45:58.\n",
      "  Batch 27,320  of  41,827.    Elapsed: 2:46:12.\n",
      "  Batch 27,360  of  41,827.    Elapsed: 2:46:27.\n",
      "  Batch 27,400  of  41,827.    Elapsed: 2:46:41.\n",
      "  Batch 27,440  of  41,827.    Elapsed: 2:46:56.\n",
      "  Batch 27,480  of  41,827.    Elapsed: 2:47:11.\n",
      "  Batch 27,520  of  41,827.    Elapsed: 2:47:25.\n",
      "  Batch 27,560  of  41,827.    Elapsed: 2:47:40.\n",
      "  Batch 27,600  of  41,827.    Elapsed: 2:47:54.\n",
      "  Batch 27,640  of  41,827.    Elapsed: 2:48:09.\n",
      "  Batch 27,680  of  41,827.    Elapsed: 2:48:23.\n",
      "  Batch 27,720  of  41,827.    Elapsed: 2:48:38.\n",
      "  Batch 27,760  of  41,827.    Elapsed: 2:48:53.\n",
      "  Batch 27,800  of  41,827.    Elapsed: 2:49:07.\n",
      "  Batch 27,840  of  41,827.    Elapsed: 2:49:22.\n",
      "  Batch 27,880  of  41,827.    Elapsed: 2:49:36.\n",
      "  Batch 27,920  of  41,827.    Elapsed: 2:49:51.\n",
      "  Batch 27,960  of  41,827.    Elapsed: 2:50:06.\n",
      "  Batch 28,000  of  41,827.    Elapsed: 2:50:20.\n",
      "  Batch 28,040  of  41,827.    Elapsed: 2:50:35.\n",
      "  Batch 28,080  of  41,827.    Elapsed: 2:50:49.\n",
      "  Batch 28,120  of  41,827.    Elapsed: 2:51:04.\n",
      "  Batch 28,160  of  41,827.    Elapsed: 2:51:18.\n",
      "  Batch 28,200  of  41,827.    Elapsed: 2:51:33.\n",
      "  Batch 28,240  of  41,827.    Elapsed: 2:51:48.\n",
      "  Batch 28,280  of  41,827.    Elapsed: 2:52:02.\n",
      "  Batch 28,320  of  41,827.    Elapsed: 2:52:17.\n",
      "  Batch 28,360  of  41,827.    Elapsed: 2:52:31.\n",
      "  Batch 28,400  of  41,827.    Elapsed: 2:52:46.\n",
      "  Batch 28,440  of  41,827.    Elapsed: 2:53:01.\n",
      "  Batch 28,480  of  41,827.    Elapsed: 2:53:15.\n",
      "  Batch 28,520  of  41,827.    Elapsed: 2:53:30.\n",
      "  Batch 28,560  of  41,827.    Elapsed: 2:53:44.\n",
      "  Batch 28,600  of  41,827.    Elapsed: 2:53:59.\n",
      "  Batch 28,640  of  41,827.    Elapsed: 2:54:14.\n",
      "  Batch 28,680  of  41,827.    Elapsed: 2:54:28.\n",
      "  Batch 28,720  of  41,827.    Elapsed: 2:54:43.\n",
      "  Batch 28,760  of  41,827.    Elapsed: 2:54:57.\n",
      "  Batch 28,800  of  41,827.    Elapsed: 2:55:12.\n",
      "  Batch 28,840  of  41,827.    Elapsed: 2:55:27.\n",
      "  Batch 28,880  of  41,827.    Elapsed: 2:55:41.\n",
      "  Batch 28,920  of  41,827.    Elapsed: 2:55:56.\n",
      "  Batch 28,960  of  41,827.    Elapsed: 2:56:10.\n",
      "  Batch 29,000  of  41,827.    Elapsed: 2:56:25.\n",
      "  Batch 29,040  of  41,827.    Elapsed: 2:56:40.\n",
      "  Batch 29,080  of  41,827.    Elapsed: 2:56:54.\n",
      "  Batch 29,120  of  41,827.    Elapsed: 2:57:09.\n",
      "  Batch 29,160  of  41,827.    Elapsed: 2:57:23.\n",
      "  Batch 29,200  of  41,827.    Elapsed: 2:57:38.\n",
      "  Batch 29,240  of  41,827.    Elapsed: 2:57:53.\n",
      "  Batch 29,280  of  41,827.    Elapsed: 2:58:07.\n",
      "  Batch 29,320  of  41,827.    Elapsed: 2:58:22.\n",
      "  Batch 29,360  of  41,827.    Elapsed: 2:58:36.\n",
      "  Batch 29,400  of  41,827.    Elapsed: 2:58:51.\n",
      "  Batch 29,440  of  41,827.    Elapsed: 2:59:06.\n",
      "  Batch 29,480  of  41,827.    Elapsed: 2:59:20.\n",
      "  Batch 29,520  of  41,827.    Elapsed: 2:59:35.\n",
      "  Batch 29,560  of  41,827.    Elapsed: 2:59:49.\n",
      "  Batch 29,600  of  41,827.    Elapsed: 3:00:04.\n",
      "  Batch 29,640  of  41,827.    Elapsed: 3:00:19.\n",
      "  Batch 29,680  of  41,827.    Elapsed: 3:00:33.\n",
      "  Batch 29,720  of  41,827.    Elapsed: 3:00:48.\n",
      "  Batch 29,760  of  41,827.    Elapsed: 3:01:02.\n",
      "  Batch 29,800  of  41,827.    Elapsed: 3:01:17.\n",
      "  Batch 29,840  of  41,827.    Elapsed: 3:01:31.\n",
      "  Batch 29,880  of  41,827.    Elapsed: 3:01:46.\n",
      "  Batch 29,920  of  41,827.    Elapsed: 3:02:01.\n",
      "  Batch 29,960  of  41,827.    Elapsed: 3:02:15.\n",
      "  Batch 30,000  of  41,827.    Elapsed: 3:02:30.\n",
      "  Batch 30,040  of  41,827.    Elapsed: 3:02:44.\n",
      "  Batch 30,080  of  41,827.    Elapsed: 3:02:59.\n",
      "  Batch 30,120  of  41,827.    Elapsed: 3:03:14.\n",
      "  Batch 30,160  of  41,827.    Elapsed: 3:03:28.\n",
      "  Batch 30,200  of  41,827.    Elapsed: 3:03:43.\n",
      "  Batch 30,240  of  41,827.    Elapsed: 3:03:57.\n",
      "  Batch 30,280  of  41,827.    Elapsed: 3:04:12.\n",
      "  Batch 30,320  of  41,827.    Elapsed: 3:04:26.\n",
      "  Batch 30,360  of  41,827.    Elapsed: 3:04:41.\n",
      "  Batch 30,400  of  41,827.    Elapsed: 3:04:56.\n",
      "  Batch 30,440  of  41,827.    Elapsed: 3:05:10.\n",
      "  Batch 30,480  of  41,827.    Elapsed: 3:05:25.\n",
      "  Batch 30,520  of  41,827.    Elapsed: 3:05:39.\n",
      "  Batch 30,560  of  41,827.    Elapsed: 3:05:54.\n",
      "  Batch 30,600  of  41,827.    Elapsed: 3:06:08.\n",
      "  Batch 30,640  of  41,827.    Elapsed: 3:06:23.\n",
      "  Batch 30,680  of  41,827.    Elapsed: 3:06:38.\n",
      "  Batch 30,720  of  41,827.    Elapsed: 3:06:52.\n",
      "  Batch 30,760  of  41,827.    Elapsed: 3:07:07.\n",
      "  Batch 30,800  of  41,827.    Elapsed: 3:07:21.\n",
      "  Batch 30,840  of  41,827.    Elapsed: 3:07:36.\n",
      "  Batch 30,880  of  41,827.    Elapsed: 3:07:50.\n",
      "  Batch 30,920  of  41,827.    Elapsed: 3:08:05.\n",
      "  Batch 30,960  of  41,827.    Elapsed: 3:08:20.\n",
      "  Batch 31,000  of  41,827.    Elapsed: 3:08:34.\n",
      "  Batch 31,040  of  41,827.    Elapsed: 3:08:49.\n",
      "  Batch 31,080  of  41,827.    Elapsed: 3:09:03.\n",
      "  Batch 31,120  of  41,827.    Elapsed: 3:09:18.\n",
      "  Batch 31,160  of  41,827.    Elapsed: 3:09:33.\n",
      "  Batch 31,200  of  41,827.    Elapsed: 3:09:47.\n",
      "  Batch 31,240  of  41,827.    Elapsed: 3:10:02.\n",
      "  Batch 31,280  of  41,827.    Elapsed: 3:10:16.\n",
      "  Batch 31,320  of  41,827.    Elapsed: 3:10:31.\n",
      "  Batch 31,360  of  41,827.    Elapsed: 3:10:45.\n",
      "  Batch 31,400  of  41,827.    Elapsed: 3:11:00.\n",
      "  Batch 31,440  of  41,827.    Elapsed: 3:11:15.\n",
      "  Batch 31,480  of  41,827.    Elapsed: 3:11:29.\n",
      "  Batch 31,520  of  41,827.    Elapsed: 3:11:44.\n",
      "  Batch 31,560  of  41,827.    Elapsed: 3:11:58.\n",
      "  Batch 31,600  of  41,827.    Elapsed: 3:12:13.\n",
      "  Batch 31,640  of  41,827.    Elapsed: 3:12:27.\n",
      "  Batch 31,680  of  41,827.    Elapsed: 3:12:42.\n",
      "  Batch 31,720  of  41,827.    Elapsed: 3:12:57.\n",
      "  Batch 31,760  of  41,827.    Elapsed: 3:13:11.\n",
      "  Batch 31,800  of  41,827.    Elapsed: 3:13:26.\n",
      "  Batch 31,840  of  41,827.    Elapsed: 3:13:40.\n",
      "  Batch 31,880  of  41,827.    Elapsed: 3:13:55.\n",
      "  Batch 31,920  of  41,827.    Elapsed: 3:14:10.\n",
      "  Batch 31,960  of  41,827.    Elapsed: 3:14:24.\n",
      "  Batch 32,000  of  41,827.    Elapsed: 3:14:39.\n",
      "  Batch 32,040  of  41,827.    Elapsed: 3:14:53.\n",
      "  Batch 32,080  of  41,827.    Elapsed: 3:15:08.\n",
      "  Batch 32,120  of  41,827.    Elapsed: 3:15:22.\n",
      "  Batch 32,160  of  41,827.    Elapsed: 3:15:37.\n",
      "  Batch 32,200  of  41,827.    Elapsed: 3:15:52.\n",
      "  Batch 32,240  of  41,827.    Elapsed: 3:16:06.\n",
      "  Batch 32,280  of  41,827.    Elapsed: 3:16:21.\n",
      "  Batch 32,320  of  41,827.    Elapsed: 3:16:35.\n",
      "  Batch 32,360  of  41,827.    Elapsed: 3:16:50.\n",
      "  Batch 32,400  of  41,827.    Elapsed: 3:17:05.\n",
      "  Batch 32,440  of  41,827.    Elapsed: 3:17:19.\n",
      "  Batch 32,480  of  41,827.    Elapsed: 3:17:34.\n",
      "  Batch 32,520  of  41,827.    Elapsed: 3:17:48.\n",
      "  Batch 32,560  of  41,827.    Elapsed: 3:18:03.\n",
      "  Batch 32,600  of  41,827.    Elapsed: 3:18:18.\n",
      "  Batch 32,640  of  41,827.    Elapsed: 3:18:32.\n",
      "  Batch 32,680  of  41,827.    Elapsed: 3:18:47.\n",
      "  Batch 32,720  of  41,827.    Elapsed: 3:19:01.\n",
      "  Batch 32,760  of  41,827.    Elapsed: 3:19:16.\n",
      "  Batch 32,800  of  41,827.    Elapsed: 3:19:31.\n",
      "  Batch 32,840  of  41,827.    Elapsed: 3:19:45.\n",
      "  Batch 32,880  of  41,827.    Elapsed: 3:20:00.\n",
      "  Batch 32,920  of  41,827.    Elapsed: 3:20:14.\n",
      "  Batch 32,960  of  41,827.    Elapsed: 3:20:29.\n",
      "  Batch 33,000  of  41,827.    Elapsed: 3:20:44.\n",
      "  Batch 33,040  of  41,827.    Elapsed: 3:20:58.\n",
      "  Batch 33,080  of  41,827.    Elapsed: 3:21:13.\n",
      "  Batch 33,120  of  41,827.    Elapsed: 3:21:27.\n",
      "  Batch 33,160  of  41,827.    Elapsed: 3:21:42.\n",
      "  Batch 33,200  of  41,827.    Elapsed: 3:21:57.\n",
      "  Batch 33,240  of  41,827.    Elapsed: 3:22:11.\n",
      "  Batch 33,280  of  41,827.    Elapsed: 3:22:26.\n",
      "  Batch 33,320  of  41,827.    Elapsed: 3:22:41.\n",
      "  Batch 33,360  of  41,827.    Elapsed: 3:22:55.\n",
      "  Batch 33,400  of  41,827.    Elapsed: 3:23:10.\n",
      "  Batch 33,440  of  41,827.    Elapsed: 3:23:24.\n",
      "  Batch 33,480  of  41,827.    Elapsed: 3:23:39.\n",
      "  Batch 33,520  of  41,827.    Elapsed: 3:23:54.\n",
      "  Batch 33,560  of  41,827.    Elapsed: 3:24:08.\n",
      "  Batch 33,600  of  41,827.    Elapsed: 3:24:23.\n",
      "  Batch 33,640  of  41,827.    Elapsed: 3:24:37.\n",
      "  Batch 33,680  of  41,827.    Elapsed: 3:24:52.\n",
      "  Batch 33,720  of  41,827.    Elapsed: 3:25:07.\n",
      "  Batch 33,760  of  41,827.    Elapsed: 3:25:21.\n",
      "  Batch 33,800  of  41,827.    Elapsed: 3:25:36.\n",
      "  Batch 33,840  of  41,827.    Elapsed: 3:25:51.\n",
      "  Batch 33,880  of  41,827.    Elapsed: 3:26:05.\n",
      "  Batch 33,920  of  41,827.    Elapsed: 3:26:20.\n",
      "  Batch 33,960  of  41,827.    Elapsed: 3:26:34.\n",
      "  Batch 34,000  of  41,827.    Elapsed: 3:26:49.\n",
      "  Batch 34,040  of  41,827.    Elapsed: 3:27:04.\n",
      "  Batch 34,080  of  41,827.    Elapsed: 3:27:18.\n",
      "  Batch 34,120  of  41,827.    Elapsed: 3:27:33.\n",
      "  Batch 34,160  of  41,827.    Elapsed: 3:27:47.\n",
      "  Batch 34,200  of  41,827.    Elapsed: 3:28:02.\n",
      "  Batch 34,240  of  41,827.    Elapsed: 3:28:17.\n",
      "  Batch 34,280  of  41,827.    Elapsed: 3:28:31.\n",
      "  Batch 34,320  of  41,827.    Elapsed: 3:28:46.\n",
      "  Batch 34,360  of  41,827.    Elapsed: 3:29:00.\n",
      "  Batch 34,400  of  41,827.    Elapsed: 3:29:15.\n",
      "  Batch 34,440  of  41,827.    Elapsed: 3:29:30.\n",
      "  Batch 34,480  of  41,827.    Elapsed: 3:29:44.\n",
      "  Batch 34,520  of  41,827.    Elapsed: 3:29:59.\n",
      "  Batch 34,560  of  41,827.    Elapsed: 3:30:13.\n",
      "  Batch 34,600  of  41,827.    Elapsed: 3:30:28.\n",
      "  Batch 34,640  of  41,827.    Elapsed: 3:30:43.\n",
      "  Batch 34,680  of  41,827.    Elapsed: 3:30:57.\n",
      "  Batch 34,720  of  41,827.    Elapsed: 3:31:12.\n",
      "  Batch 34,760  of  41,827.    Elapsed: 3:31:26.\n",
      "  Batch 34,800  of  41,827.    Elapsed: 3:31:41.\n",
      "  Batch 34,840  of  41,827.    Elapsed: 3:31:56.\n",
      "  Batch 34,880  of  41,827.    Elapsed: 3:32:10.\n",
      "  Batch 34,920  of  41,827.    Elapsed: 3:32:25.\n",
      "  Batch 34,960  of  41,827.    Elapsed: 3:32:39.\n",
      "  Batch 35,000  of  41,827.    Elapsed: 3:32:54.\n",
      "  Batch 35,040  of  41,827.    Elapsed: 3:33:09.\n",
      "  Batch 35,080  of  41,827.    Elapsed: 3:33:23.\n",
      "  Batch 35,120  of  41,827.    Elapsed: 3:33:38.\n",
      "  Batch 35,160  of  41,827.    Elapsed: 3:33:52.\n",
      "  Batch 35,200  of  41,827.    Elapsed: 3:34:07.\n",
      "  Batch 35,240  of  41,827.    Elapsed: 3:34:22.\n",
      "  Batch 35,280  of  41,827.    Elapsed: 3:34:36.\n",
      "  Batch 35,320  of  41,827.    Elapsed: 3:34:51.\n",
      "  Batch 35,360  of  41,827.    Elapsed: 3:35:05.\n",
      "  Batch 35,400  of  41,827.    Elapsed: 3:35:20.\n",
      "  Batch 35,440  of  41,827.    Elapsed: 3:35:34.\n",
      "  Batch 35,480  of  41,827.    Elapsed: 3:35:49.\n",
      "  Batch 35,520  of  41,827.    Elapsed: 3:36:04.\n",
      "  Batch 35,560  of  41,827.    Elapsed: 3:36:18.\n",
      "  Batch 35,600  of  41,827.    Elapsed: 3:36:33.\n",
      "  Batch 35,640  of  41,827.    Elapsed: 3:36:47.\n",
      "  Batch 35,680  of  41,827.    Elapsed: 3:37:02.\n",
      "  Batch 35,720  of  41,827.    Elapsed: 3:37:17.\n",
      "  Batch 35,760  of  41,827.    Elapsed: 3:37:31.\n",
      "  Batch 35,800  of  41,827.    Elapsed: 3:37:46.\n",
      "  Batch 35,840  of  41,827.    Elapsed: 3:38:00.\n",
      "  Batch 35,880  of  41,827.    Elapsed: 3:38:15.\n",
      "  Batch 35,920  of  41,827.    Elapsed: 3:38:30.\n",
      "  Batch 35,960  of  41,827.    Elapsed: 3:38:44.\n",
      "  Batch 36,000  of  41,827.    Elapsed: 3:38:59.\n",
      "  Batch 36,040  of  41,827.    Elapsed: 3:39:13.\n",
      "  Batch 36,080  of  41,827.    Elapsed: 3:39:28.\n",
      "  Batch 36,120  of  41,827.    Elapsed: 3:39:42.\n",
      "  Batch 36,160  of  41,827.    Elapsed: 3:39:57.\n",
      "  Batch 36,200  of  41,827.    Elapsed: 3:40:12.\n",
      "  Batch 36,240  of  41,827.    Elapsed: 3:40:26.\n",
      "  Batch 36,280  of  41,827.    Elapsed: 3:40:41.\n",
      "  Batch 36,320  of  41,827.    Elapsed: 3:40:55.\n",
      "  Batch 36,360  of  41,827.    Elapsed: 3:41:10.\n",
      "  Batch 36,400  of  41,827.    Elapsed: 3:41:25.\n",
      "  Batch 36,440  of  41,827.    Elapsed: 3:41:39.\n",
      "  Batch 36,480  of  41,827.    Elapsed: 3:41:54.\n",
      "  Batch 36,520  of  41,827.    Elapsed: 3:42:08.\n",
      "  Batch 36,560  of  41,827.    Elapsed: 3:42:23.\n",
      "  Batch 36,600  of  41,827.    Elapsed: 3:42:38.\n",
      "  Batch 36,640  of  41,827.    Elapsed: 3:42:52.\n",
      "  Batch 36,680  of  41,827.    Elapsed: 3:43:07.\n",
      "  Batch 36,720  of  41,827.    Elapsed: 3:43:21.\n",
      "  Batch 36,760  of  41,827.    Elapsed: 3:43:36.\n",
      "  Batch 36,800  of  41,827.    Elapsed: 3:43:51.\n",
      "  Batch 36,840  of  41,827.    Elapsed: 3:44:05.\n",
      "  Batch 36,880  of  41,827.    Elapsed: 3:44:20.\n",
      "  Batch 36,920  of  41,827.    Elapsed: 3:44:34.\n",
      "  Batch 36,960  of  41,827.    Elapsed: 3:44:49.\n",
      "  Batch 37,000  of  41,827.    Elapsed: 3:45:04.\n",
      "  Batch 37,040  of  41,827.    Elapsed: 3:45:18.\n",
      "  Batch 37,080  of  41,827.    Elapsed: 3:45:33.\n",
      "  Batch 37,120  of  41,827.    Elapsed: 3:45:47.\n",
      "  Batch 37,160  of  41,827.    Elapsed: 3:46:02.\n",
      "  Batch 37,200  of  41,827.    Elapsed: 3:46:17.\n",
      "  Batch 37,240  of  41,827.    Elapsed: 3:46:31.\n",
      "  Batch 37,280  of  41,827.    Elapsed: 3:46:46.\n",
      "  Batch 37,320  of  41,827.    Elapsed: 3:47:00.\n",
      "  Batch 37,360  of  41,827.    Elapsed: 3:47:15.\n",
      "  Batch 37,400  of  41,827.    Elapsed: 3:47:30.\n",
      "  Batch 37,440  of  41,827.    Elapsed: 3:47:44.\n",
      "  Batch 37,480  of  41,827.    Elapsed: 3:47:59.\n",
      "  Batch 37,520  of  41,827.    Elapsed: 3:48:13.\n",
      "  Batch 37,560  of  41,827.    Elapsed: 3:48:28.\n",
      "  Batch 37,600  of  41,827.    Elapsed: 3:48:43.\n",
      "  Batch 37,640  of  41,827.    Elapsed: 3:48:57.\n",
      "  Batch 37,680  of  41,827.    Elapsed: 3:49:12.\n",
      "  Batch 37,720  of  41,827.    Elapsed: 3:49:27.\n",
      "  Batch 37,760  of  41,827.    Elapsed: 3:49:41.\n",
      "  Batch 37,800  of  41,827.    Elapsed: 3:49:56.\n",
      "  Batch 37,840  of  41,827.    Elapsed: 3:50:10.\n",
      "  Batch 37,880  of  41,827.    Elapsed: 3:50:25.\n",
      "  Batch 37,920  of  41,827.    Elapsed: 3:50:40.\n",
      "  Batch 37,960  of  41,827.    Elapsed: 3:50:54.\n",
      "  Batch 38,000  of  41,827.    Elapsed: 3:51:09.\n",
      "  Batch 38,040  of  41,827.    Elapsed: 3:51:23.\n",
      "  Batch 38,080  of  41,827.    Elapsed: 3:51:38.\n",
      "  Batch 38,120  of  41,827.    Elapsed: 3:51:53.\n",
      "  Batch 38,160  of  41,827.    Elapsed: 3:52:07.\n",
      "  Batch 38,200  of  41,827.    Elapsed: 3:52:22.\n",
      "  Batch 38,240  of  41,827.    Elapsed: 3:52:37.\n",
      "  Batch 38,280  of  41,827.    Elapsed: 3:52:51.\n",
      "  Batch 38,320  of  41,827.    Elapsed: 3:53:06.\n",
      "  Batch 38,360  of  41,827.    Elapsed: 3:53:20.\n",
      "  Batch 38,400  of  41,827.    Elapsed: 3:53:35.\n",
      "  Batch 38,440  of  41,827.    Elapsed: 3:53:50.\n",
      "  Batch 38,480  of  41,827.    Elapsed: 3:54:04.\n",
      "  Batch 38,520  of  41,827.    Elapsed: 3:54:19.\n",
      "  Batch 38,560  of  41,827.    Elapsed: 3:54:34.\n",
      "  Batch 38,600  of  41,827.    Elapsed: 3:54:48.\n",
      "  Batch 38,640  of  41,827.    Elapsed: 3:55:03.\n",
      "  Batch 38,680  of  41,827.    Elapsed: 3:55:17.\n",
      "  Batch 38,720  of  41,827.    Elapsed: 3:55:32.\n",
      "  Batch 38,760  of  41,827.    Elapsed: 3:55:47.\n",
      "  Batch 38,800  of  41,827.    Elapsed: 3:56:01.\n",
      "  Batch 38,840  of  41,827.    Elapsed: 3:56:16.\n",
      "  Batch 38,880  of  41,827.    Elapsed: 3:56:31.\n",
      "  Batch 38,920  of  41,827.    Elapsed: 3:56:45.\n",
      "  Batch 38,960  of  41,827.    Elapsed: 3:57:00.\n",
      "  Batch 39,000  of  41,827.    Elapsed: 3:57:14.\n",
      "  Batch 39,040  of  41,827.    Elapsed: 3:57:29.\n",
      "  Batch 39,080  of  41,827.    Elapsed: 3:57:44.\n",
      "  Batch 39,120  of  41,827.    Elapsed: 3:57:58.\n",
      "  Batch 39,160  of  41,827.    Elapsed: 3:58:13.\n",
      "  Batch 39,200  of  41,827.    Elapsed: 3:58:27.\n",
      "  Batch 39,240  of  41,827.    Elapsed: 3:58:42.\n",
      "  Batch 39,280  of  41,827.    Elapsed: 3:58:57.\n",
      "  Batch 39,320  of  41,827.    Elapsed: 3:59:11.\n",
      "  Batch 39,360  of  41,827.    Elapsed: 3:59:26.\n",
      "  Batch 39,400  of  41,827.    Elapsed: 3:59:41.\n",
      "  Batch 39,440  of  41,827.    Elapsed: 3:59:55.\n",
      "  Batch 39,480  of  41,827.    Elapsed: 4:00:10.\n",
      "  Batch 39,520  of  41,827.    Elapsed: 4:00:25.\n",
      "  Batch 39,560  of  41,827.    Elapsed: 4:00:39.\n",
      "  Batch 39,600  of  41,827.    Elapsed: 4:00:54.\n",
      "  Batch 39,640  of  41,827.    Elapsed: 4:01:08.\n",
      "  Batch 39,680  of  41,827.    Elapsed: 4:01:23.\n",
      "  Batch 39,720  of  41,827.    Elapsed: 4:01:38.\n",
      "  Batch 39,760  of  41,827.    Elapsed: 4:01:52.\n",
      "  Batch 39,800  of  41,827.    Elapsed: 4:02:07.\n",
      "  Batch 39,840  of  41,827.    Elapsed: 4:02:21.\n",
      "  Batch 39,880  of  41,827.    Elapsed: 4:02:36.\n",
      "  Batch 39,920  of  41,827.    Elapsed: 4:02:51.\n",
      "  Batch 39,960  of  41,827.    Elapsed: 4:03:05.\n",
      "  Batch 40,000  of  41,827.    Elapsed: 4:03:20.\n",
      "  Batch 40,040  of  41,827.    Elapsed: 4:03:34.\n",
      "  Batch 40,080  of  41,827.    Elapsed: 4:03:49.\n",
      "  Batch 40,120  of  41,827.    Elapsed: 4:04:03.\n",
      "  Batch 40,160  of  41,827.    Elapsed: 4:04:18.\n",
      "  Batch 40,200  of  41,827.    Elapsed: 4:04:33.\n",
      "  Batch 40,240  of  41,827.    Elapsed: 4:04:47.\n",
      "  Batch 40,280  of  41,827.    Elapsed: 4:05:02.\n",
      "  Batch 40,320  of  41,827.    Elapsed: 4:05:16.\n",
      "  Batch 40,360  of  41,827.    Elapsed: 4:05:31.\n",
      "  Batch 40,400  of  41,827.    Elapsed: 4:05:45.\n",
      "  Batch 40,440  of  41,827.    Elapsed: 4:06:00.\n",
      "  Batch 40,480  of  41,827.    Elapsed: 4:06:15.\n",
      "  Batch 40,520  of  41,827.    Elapsed: 4:06:29.\n",
      "  Batch 40,560  of  41,827.    Elapsed: 4:06:44.\n",
      "  Batch 40,600  of  41,827.    Elapsed: 4:06:58.\n",
      "  Batch 40,640  of  41,827.    Elapsed: 4:07:13.\n",
      "  Batch 40,680  of  41,827.    Elapsed: 4:07:28.\n",
      "  Batch 40,720  of  41,827.    Elapsed: 4:07:42.\n",
      "  Batch 40,760  of  41,827.    Elapsed: 4:07:57.\n",
      "  Batch 40,800  of  41,827.    Elapsed: 4:08:12.\n",
      "  Batch 40,840  of  41,827.    Elapsed: 4:08:26.\n",
      "  Batch 40,880  of  41,827.    Elapsed: 4:08:41.\n",
      "  Batch 40,920  of  41,827.    Elapsed: 4:08:55.\n",
      "  Batch 40,960  of  41,827.    Elapsed: 4:09:10.\n",
      "  Batch 41,000  of  41,827.    Elapsed: 4:09:25.\n",
      "  Batch 41,040  of  41,827.    Elapsed: 4:09:39.\n",
      "  Batch 41,080  of  41,827.    Elapsed: 4:09:54.\n",
      "  Batch 41,120  of  41,827.    Elapsed: 4:10:08.\n",
      "  Batch 41,160  of  41,827.    Elapsed: 4:10:23.\n",
      "  Batch 41,200  of  41,827.    Elapsed: 4:10:38.\n",
      "  Batch 41,240  of  41,827.    Elapsed: 4:10:52.\n",
      "  Batch 41,280  of  41,827.    Elapsed: 4:11:07.\n",
      "  Batch 41,320  of  41,827.    Elapsed: 4:11:21.\n",
      "  Batch 41,360  of  41,827.    Elapsed: 4:11:36.\n",
      "  Batch 41,400  of  41,827.    Elapsed: 4:11:51.\n",
      "  Batch 41,440  of  41,827.    Elapsed: 4:12:05.\n",
      "  Batch 41,480  of  41,827.    Elapsed: 4:12:20.\n",
      "  Batch 41,520  of  41,827.    Elapsed: 4:12:34.\n",
      "  Batch 41,560  of  41,827.    Elapsed: 4:12:49.\n",
      "  Batch 41,600  of  41,827.    Elapsed: 4:13:04.\n",
      "  Batch 41,640  of  41,827.    Elapsed: 4:13:18.\n",
      "  Batch 41,680  of  41,827.    Elapsed: 4:13:33.\n",
      "  Batch 41,720  of  41,827.    Elapsed: 4:13:47.\n",
      "  Batch 41,760  of  41,827.    Elapsed: 4:14:02.\n",
      "  Batch 41,800  of  41,827.    Elapsed: 4:14:16.\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 4:14:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:08:49\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  41,827.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  41,827.    Elapsed: 0:00:29.\n",
      "  Batch   120  of  41,827.    Elapsed: 0:00:44.\n",
      "  Batch   160  of  41,827.    Elapsed: 0:00:59.\n",
      "  Batch   200  of  41,827.    Elapsed: 0:01:13.\n",
      "  Batch   240  of  41,827.    Elapsed: 0:01:28.\n",
      "  Batch   280  of  41,827.    Elapsed: 0:01:43.\n",
      "  Batch   320  of  41,827.    Elapsed: 0:01:57.\n",
      "  Batch   360  of  41,827.    Elapsed: 0:02:12.\n",
      "  Batch   400  of  41,827.    Elapsed: 0:02:27.\n",
      "  Batch   440  of  41,827.    Elapsed: 0:02:41.\n",
      "  Batch   480  of  41,827.    Elapsed: 0:02:56.\n",
      "  Batch   520  of  41,827.    Elapsed: 0:03:11.\n",
      "  Batch   560  of  41,827.    Elapsed: 0:03:25.\n",
      "  Batch   600  of  41,827.    Elapsed: 0:03:40.\n",
      "  Batch   640  of  41,827.    Elapsed: 0:03:54.\n",
      "  Batch   680  of  41,827.    Elapsed: 0:04:09.\n",
      "  Batch   720  of  41,827.    Elapsed: 0:04:24.\n",
      "  Batch   760  of  41,827.    Elapsed: 0:04:38.\n",
      "  Batch   800  of  41,827.    Elapsed: 0:04:53.\n",
      "  Batch   840  of  41,827.    Elapsed: 0:05:08.\n",
      "  Batch   880  of  41,827.    Elapsed: 0:05:22.\n",
      "  Batch   920  of  41,827.    Elapsed: 0:05:37.\n",
      "  Batch   960  of  41,827.    Elapsed: 0:05:52.\n",
      "  Batch 1,000  of  41,827.    Elapsed: 0:06:06.\n",
      "  Batch 1,040  of  41,827.    Elapsed: 0:06:21.\n",
      "  Batch 1,080  of  41,827.    Elapsed: 0:06:36.\n",
      "  Batch 1,120  of  41,827.    Elapsed: 0:06:50.\n",
      "  Batch 1,160  of  41,827.    Elapsed: 0:07:05.\n",
      "  Batch 1,200  of  41,827.    Elapsed: 0:07:19.\n",
      "  Batch 1,240  of  41,827.    Elapsed: 0:07:34.\n",
      "  Batch 1,280  of  41,827.    Elapsed: 0:07:49.\n",
      "  Batch 1,320  of  41,827.    Elapsed: 0:08:03.\n",
      "  Batch 1,360  of  41,827.    Elapsed: 0:08:18.\n",
      "  Batch 1,400  of  41,827.    Elapsed: 0:08:33.\n",
      "  Batch 1,440  of  41,827.    Elapsed: 0:08:47.\n",
      "  Batch 1,480  of  41,827.    Elapsed: 0:09:02.\n",
      "  Batch 1,520  of  41,827.    Elapsed: 0:09:16.\n",
      "  Batch 1,560  of  41,827.    Elapsed: 0:09:31.\n",
      "  Batch 1,600  of  41,827.    Elapsed: 0:09:46.\n",
      "  Batch 1,640  of  41,827.    Elapsed: 0:10:00.\n",
      "  Batch 1,680  of  41,827.    Elapsed: 0:10:15.\n",
      "  Batch 1,720  of  41,827.    Elapsed: 0:10:30.\n",
      "  Batch 1,760  of  41,827.    Elapsed: 0:10:44.\n",
      "  Batch 1,800  of  41,827.    Elapsed: 0:10:59.\n",
      "  Batch 1,840  of  41,827.    Elapsed: 0:11:14.\n",
      "  Batch 1,880  of  41,827.    Elapsed: 0:11:28.\n",
      "  Batch 1,920  of  41,827.    Elapsed: 0:11:43.\n",
      "  Batch 1,960  of  41,827.    Elapsed: 0:11:58.\n",
      "  Batch 2,000  of  41,827.    Elapsed: 0:12:12.\n",
      "  Batch 2,040  of  41,827.    Elapsed: 0:12:27.\n",
      "  Batch 2,080  of  41,827.    Elapsed: 0:12:41.\n",
      "  Batch 2,120  of  41,827.    Elapsed: 0:12:56.\n",
      "  Batch 2,160  of  41,827.    Elapsed: 0:13:11.\n",
      "  Batch 2,200  of  41,827.    Elapsed: 0:13:25.\n",
      "  Batch 2,240  of  41,827.    Elapsed: 0:13:40.\n",
      "  Batch 2,280  of  41,827.    Elapsed: 0:13:55.\n",
      "  Batch 2,320  of  41,827.    Elapsed: 0:14:09.\n",
      "  Batch 2,360  of  41,827.    Elapsed: 0:14:24.\n",
      "  Batch 2,400  of  41,827.    Elapsed: 0:14:39.\n",
      "  Batch 2,440  of  41,827.    Elapsed: 0:14:53.\n",
      "  Batch 2,480  of  41,827.    Elapsed: 0:15:08.\n",
      "  Batch 2,520  of  41,827.    Elapsed: 0:15:22.\n",
      "  Batch 2,560  of  41,827.    Elapsed: 0:15:37.\n",
      "  Batch 2,600  of  41,827.    Elapsed: 0:15:52.\n",
      "  Batch 2,640  of  41,827.    Elapsed: 0:16:06.\n",
      "  Batch 2,680  of  41,827.    Elapsed: 0:16:21.\n",
      "  Batch 2,720  of  41,827.    Elapsed: 0:16:36.\n",
      "  Batch 2,760  of  41,827.    Elapsed: 0:16:50.\n",
      "  Batch 2,800  of  41,827.    Elapsed: 0:17:05.\n",
      "  Batch 2,840  of  41,827.    Elapsed: 0:17:19.\n",
      "  Batch 2,880  of  41,827.    Elapsed: 0:17:34.\n",
      "  Batch 2,920  of  41,827.    Elapsed: 0:17:49.\n",
      "  Batch 2,960  of  41,827.    Elapsed: 0:18:03.\n",
      "  Batch 3,000  of  41,827.    Elapsed: 0:18:18.\n",
      "  Batch 3,040  of  41,827.    Elapsed: 0:18:32.\n",
      "  Batch 3,080  of  41,827.    Elapsed: 0:18:47.\n",
      "  Batch 3,120  of  41,827.    Elapsed: 0:19:02.\n",
      "  Batch 3,160  of  41,827.    Elapsed: 0:19:16.\n",
      "  Batch 3,200  of  41,827.    Elapsed: 0:19:31.\n",
      "  Batch 3,240  of  41,827.    Elapsed: 0:19:46.\n",
      "  Batch 3,280  of  41,827.    Elapsed: 0:20:00.\n",
      "  Batch 3,320  of  41,827.    Elapsed: 0:20:15.\n",
      "  Batch 3,360  of  41,827.    Elapsed: 0:20:30.\n",
      "  Batch 3,400  of  41,827.    Elapsed: 0:20:44.\n",
      "  Batch 3,440  of  41,827.    Elapsed: 0:20:59.\n",
      "  Batch 3,480  of  41,827.    Elapsed: 0:21:14.\n",
      "  Batch 3,520  of  41,827.    Elapsed: 0:21:28.\n",
      "  Batch 3,560  of  41,827.    Elapsed: 0:21:43.\n",
      "  Batch 3,600  of  41,827.    Elapsed: 0:21:58.\n",
      "  Batch 3,640  of  41,827.    Elapsed: 0:22:12.\n",
      "  Batch 3,680  of  41,827.    Elapsed: 0:22:27.\n",
      "  Batch 3,720  of  41,827.    Elapsed: 0:22:41.\n",
      "  Batch 3,760  of  41,827.    Elapsed: 0:22:56.\n",
      "  Batch 3,800  of  41,827.    Elapsed: 0:23:11.\n",
      "  Batch 3,840  of  41,827.    Elapsed: 0:23:25.\n",
      "  Batch 3,880  of  41,827.    Elapsed: 0:23:40.\n",
      "  Batch 3,920  of  41,827.    Elapsed: 0:23:55.\n",
      "  Batch 3,960  of  41,827.    Elapsed: 0:24:09.\n",
      "  Batch 4,000  of  41,827.    Elapsed: 0:24:24.\n",
      "  Batch 4,040  of  41,827.    Elapsed: 0:24:38.\n",
      "  Batch 4,080  of  41,827.    Elapsed: 0:24:53.\n",
      "  Batch 4,120  of  41,827.    Elapsed: 0:25:08.\n",
      "  Batch 4,160  of  41,827.    Elapsed: 0:25:22.\n",
      "  Batch 4,200  of  41,827.    Elapsed: 0:25:37.\n",
      "  Batch 4,240  of  41,827.    Elapsed: 0:25:52.\n",
      "  Batch 4,280  of  41,827.    Elapsed: 0:26:06.\n",
      "  Batch 4,320  of  41,827.    Elapsed: 0:26:21.\n",
      "  Batch 4,360  of  41,827.    Elapsed: 0:26:36.\n",
      "  Batch 4,400  of  41,827.    Elapsed: 0:26:50.\n",
      "  Batch 4,440  of  41,827.    Elapsed: 0:27:05.\n",
      "  Batch 4,480  of  41,827.    Elapsed: 0:27:19.\n",
      "  Batch 4,520  of  41,827.    Elapsed: 0:27:34.\n",
      "  Batch 4,560  of  41,827.    Elapsed: 0:27:49.\n",
      "  Batch 4,600  of  41,827.    Elapsed: 0:28:03.\n",
      "  Batch 4,640  of  41,827.    Elapsed: 0:28:18.\n",
      "  Batch 4,680  of  41,827.    Elapsed: 0:28:33.\n",
      "  Batch 4,720  of  41,827.    Elapsed: 0:28:47.\n",
      "  Batch 4,760  of  41,827.    Elapsed: 0:29:02.\n",
      "  Batch 4,800  of  41,827.    Elapsed: 0:29:16.\n",
      "  Batch 4,840  of  41,827.    Elapsed: 0:29:31.\n",
      "  Batch 4,880  of  41,827.    Elapsed: 0:29:46.\n",
      "  Batch 4,920  of  41,827.    Elapsed: 0:30:00.\n",
      "  Batch 4,960  of  41,827.    Elapsed: 0:30:15.\n",
      "  Batch 5,000  of  41,827.    Elapsed: 0:30:30.\n",
      "  Batch 5,040  of  41,827.    Elapsed: 0:30:44.\n",
      "  Batch 5,080  of  41,827.    Elapsed: 0:30:59.\n",
      "  Batch 5,120  of  41,827.    Elapsed: 0:31:14.\n",
      "  Batch 5,160  of  41,827.    Elapsed: 0:31:28.\n",
      "  Batch 5,200  of  41,827.    Elapsed: 0:31:43.\n",
      "  Batch 5,240  of  41,827.    Elapsed: 0:31:57.\n",
      "  Batch 5,280  of  41,827.    Elapsed: 0:32:12.\n",
      "  Batch 5,320  of  41,827.    Elapsed: 0:32:27.\n",
      "  Batch 5,360  of  41,827.    Elapsed: 0:32:41.\n",
      "  Batch 5,400  of  41,827.    Elapsed: 0:32:56.\n",
      "  Batch 5,440  of  41,827.    Elapsed: 0:33:11.\n",
      "  Batch 5,480  of  41,827.    Elapsed: 0:33:25.\n",
      "  Batch 5,520  of  41,827.    Elapsed: 0:33:40.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsQMY-7R5kXN"
   },
   "source": [
    "Achieved a 91% accuracy after the first epoch and did not improve afterwards.\n",
    "This shows that our model was successful and we could in fact predict the severity of an accident by using the description of it. So when an operator hears the description of an accident and runs it against our model they would know if they should prioritize getting to that location."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BERT Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0236d515a0bd4daab9a971b856c5e1cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2eab9494b8dd4e3a8b476f35511311dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c9280a2c3ca46c1a5cd6c30e04e4341": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b09914bc13bf4bf490704cf72ba714c2",
      "placeholder": "​",
      "style": "IPY_MODEL_2eab9494b8dd4e3a8b476f35511311dd",
      "value": " 232k/232k [00:00&lt;00:00, 574kB/s]"
     }
    },
    "40f8285db49845b69ed7cc52ab35612f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7a35f3310d54025ad3524ec1ebfc82e",
       "IPY_MODEL_3c9280a2c3ca46c1a5cd6c30e04e4341"
      ],
      "layout": "IPY_MODEL_7723bccb180d49f0a0954200c8f7cf05"
     }
    },
    "7723bccb180d49f0a0954200c8f7cf05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f34dd57f16b443c819186b2e8cccb22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b09914bc13bf4bf490704cf72ba714c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7a35f3310d54025ad3524ec1ebfc82e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f34dd57f16b443c819186b2e8cccb22",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0236d515a0bd4daab9a971b856c5e1cd",
      "value": 231508
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
